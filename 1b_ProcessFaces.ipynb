{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install torch and pandas before running\n",
    "%reset -f\n",
    "\n",
    "import sys, os, cv2, glob, json, gc\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import circstat as CS\n",
    "import scipy as sc\n",
    "import math\n",
    "\n",
    "from processing import *\n",
    "from kinematics import *\n",
    "from skeleton import *\n",
    "\n",
    "gc.collect()\n",
    "OVERWRITE = True\n",
    "USE_CENTER_INSTANCE = False\n",
    "USE_BEST_INSTANCE = True\n",
    "dataset = 'CHOP_face'\n",
    "\n",
    "json_path = f'./data/Infant Pose Data/{dataset}/annotations'\n",
    "json_files = os.listdir(json_path)\n",
    "directory = f'./data'\n",
    "\n",
    "save_path = f'./pose_estimates/{dataset}_norm'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "kp_mapping = {\n",
    "    **{i: \"Chin\" for i in range(0, 33)},\n",
    "    **{i: \"Right_brow\" for i in range(33, 42)},\n",
    "    **{i: \"Left_brow\" for i in range(42, 51)},\n",
    "    **{i: \"Nose\" for i in range(51, 66)},\n",
    "    **{i: \"Right_Eye\" for i in range(66, 75)},\n",
    "    **{i: \"Left_Eye\" for i in range(75, 84)},\n",
    "    **{i: \"Mouth\" for i in range(84, 104)},\n",
    "    104: \"Right_Pupil\",\n",
    "    105: \"Left_Pupil\"\n",
    "}\n",
    "\n",
    "# Define the DataFrame columns as specified\n",
    "columns = ['video_number', 'video', 'bp', 'frame', 'x', 'y', 'c','fps', 'pixel_x', 'pixel_y', 'time', 'part_idx']\n",
    "data = []  # This will hold the data to be loaded into the DataFrame\n",
    "\n",
    "vid_info = pd.read_csv(f'./data/{dataset}_video_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "USE_CENTER_INSTANCE = True\n",
    "USE_BEST_INSTANCE = False\n",
    "OVERWRITE = False\n",
    "columns = [\"file_number\", \"fname\", \"bp\", \"frame_id\", \"x\", \"y\", \"c\", \"fps\", \"pixel_x\", \"pixel_y\", \"time\", \"part_idx\"]\n",
    "\n",
    "def process_file(args):\n",
    "    \"\"\"Function to process a single file.\"\"\"\n",
    "    file_number, file, json_path, save_path, vid_info, kp_mapping = args\n",
    "    \n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(json_path, file)\n",
    "    fname = file.split('.')[0]\n",
    "    interim = []\n",
    "\n",
    "    if not OVERWRITE and os.path.exists(f'{save_path}/{fname}.csv'):\n",
    "        return  # Skip if already exists and not overwriting\n",
    "\n",
    "    try:\n",
    "        # Open and load the JSON data\n",
    "        with open(file_path, 'r') as f:\n",
    "            frames = json.load(f)\n",
    "            info = vid_info[vid_info['video'] == fname]\n",
    "            fps = info['fps'].values[0]\n",
    "\n",
    "            pixel_x = info['width'].values[0]\n",
    "            pixel_y = info['height'].values[0]\n",
    "            \n",
    "            center_x = pixel_x / 2\n",
    "            center_y = pixel_y / 2\n",
    "            \n",
    "            # Iterate through each frame in the JSON file\n",
    "            for frame in frames:\n",
    "                frame_id = frame['frame_id']\n",
    "                if 'instances' in frame and len(frame['instances']) > 0:\n",
    "\n",
    "                    if USE_CENTER_INSTANCE:\n",
    "                        instance_id = get_center_instance(frame['instances'], center_x, center_y)\n",
    "                    elif USE_BEST_INSTANCE:\n",
    "                        instance_id = get_best_instance(frame['instances'])\n",
    "                    else:\n",
    "                        instance_id = 0\n",
    "\n",
    "                    keypoints = frame['instances'][instance_id]['keypoints']\n",
    "                    confidence = frame['instances'][instance_id]['keypoint_scores']\n",
    "\n",
    "                    # Iterate through each keypoint\n",
    "                    for part_idx, (x, y) in enumerate(keypoints):\n",
    "                        bp = kp_mapping[part_idx]\n",
    "                        time = frame_id / fps\n",
    "                        c = confidence[part_idx]\n",
    "\n",
    "                        row = [file_number, fname, bp, frame_id, x, y, c, fps, pixel_x, pixel_y, time, part_idx]\n",
    "                        interim.append(row)\n",
    "\n",
    "        interim_df = pd.DataFrame(interim, columns=columns)\n",
    "        interim_df.to_csv(f'{save_path}/{fname}.csv', index=False)\n",
    "        return\n",
    "    \n",
    "    except Exception as e:\n",
    "        return\n",
    "    \n",
    "def process_annotations_multiprocess(json_files, json_path, save_path, vid_info, kp_mapping):\n",
    "    \"\"\"Run the annotation processing using multiprocessing.\"\"\"\n",
    "    args = [\n",
    "        (file_number, file, json_path, save_path, vid_info, kp_mapping)\n",
    "        for file_number, file in enumerate(json_files)\n",
    "    ]\n",
    "\n",
    "    # Set up a pool of workers\n",
    "    with Pool(processes=20) as pool:\n",
    "        pool.map(process_file, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_annotations_multiprocess(json_files, json_path, save_path, vid_info, kp_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_coordinates(points, center, angle_degrees):\n",
    "    \"\"\"\n",
    "    Rotates a series of x, y coordinates around a specific point by a given angle.\n",
    "\n",
    "    Args:\n",
    "        points (list of tuples): List of (x, y) coordinates to be rotated.\n",
    "        center (tuple): The (cx, cy) coordinates of the rotation center.\n",
    "        angle_degrees (float): The rotation angle in degrees (positive for counter-clockwise).\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Rotated (x, y) coordinates.\n",
    "    \"\"\"\n",
    "    cx, cy = center\n",
    "    angle_radians = math.radians(angle_degrees)\n",
    "    cos_theta = math.cos(angle_radians)\n",
    "    sin_theta = math.sin(angle_radians)\n",
    "\n",
    "    rotated_points = []\n",
    "    for x, y in points:\n",
    "        # Translate point to origin\n",
    "        translated_x = x - cx\n",
    "        translated_y = y - cy\n",
    "        \n",
    "        # Apply rotation matrix\n",
    "        rotated_x = translated_x * cos_theta - translated_y * sin_theta\n",
    "        rotated_y = translated_x * sin_theta + translated_y * cos_theta\n",
    "        \n",
    "        # Translate point back to its original position\n",
    "        final_x = rotated_x + cx\n",
    "        final_y = rotated_y + cy\n",
    "        \n",
    "        rotated_points.append((final_x, final_y))\n",
    "\n",
    "    return rotated_points\n",
    "\n",
    "def find_alignment_angle(points):\n",
    "    \"\"\"\n",
    "    Finds the angle to align a set of points so point[0] is to the left of point[1], ensuring the face is head up.\n",
    "\n",
    "    Args:\n",
    "        points (list of tuples): List of (x, y) coordinates where point[0] and point[1] define the face.\n",
    "\n",
    "    Returns:\n",
    "        float: The angle in degrees to align the face upright.\n",
    "    \"\"\"\n",
    "    x1, y1 = points[0]\n",
    "    x2, y2 = points[1]\n",
    "\n",
    "    # Compute angle to horizontal axis\n",
    "    delta_x = x2 - x1\n",
    "    delta_y = y2 - y1\n",
    "    angle_radians = math.atan2(delta_y, delta_x)\n",
    "    angle_degrees = math.degrees(angle_radians)\n",
    "\n",
    "    # Adjust to ensure the face is 'head up'\n",
    "    if x1 < x2:\n",
    "        angle_degrees += 180\n",
    "\n",
    "    return -angle_degrees\n",
    "\n",
    "def scale_coordinates(points):\n",
    "    \"\"\"\n",
    "    Scales a series of x, y coordinates proportionally to ensure a face height of 1.\n",
    "\n",
    "    Args:\n",
    "        points (list of tuples): List of (x, y) coordinates.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Scaled (x, y) coordinates.\n",
    "    \"\"\"\n",
    "    all_x_y = pd.DataFrame(points, columns=['x', 'y'])\n",
    "    min_y = all_x_y['y'].min()\n",
    "    max_y = all_x_y['y'].max()\n",
    "    height = max_y - min_y\n",
    "\n",
    "    scaled_points = []\n",
    "    for x, y in points:\n",
    "        scaled_x = x / height \n",
    "        scaled_y = (y - min_y) / height \n",
    "        scaled_points.append((scaled_x, scaled_y))\n",
    "\n",
    "    return scaled_points\n",
    "\n",
    "def move_to_center(points, center):\n",
    "    \"\"\"\n",
    "    Moves a series of x, y coordinates to the origin (0, 0) by subtracting the center coordinates.\n",
    "\n",
    "    Args:\n",
    "        points (list of tuples): List of (x, y) coordinates.\n",
    "        center (tuple): The (cx, cy) coordinates of the center.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Moved (x, y) coordinates.\n",
    "    \"\"\"\n",
    "    cx, cy = center\n",
    "    moved_points = [(x - cx, y - cy) for x, y in points]\n",
    "    return moved_points\n",
    "\n",
    "\n",
    "def move_and_rotate_keypoints_updated(df):\n",
    "    \"\"\"\n",
    "    Reads a CSV file, processes keypoints (move, rotate, normalize), and saves to a new CSV.\n",
    "\n",
    "    Parameters:\n",
    "    - input_csv (str): Path to the input CSV file.\n",
    "    - output_csv (str): Path to save the output CSV file.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    #df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    required_columns = ['video', 'frame', 'part_idx', 'x', 'y']\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(f\"Input CSV must contain the following columns: {required_columns}\")\n",
    "    \n",
    "    # Keypoint indexes to be aligned\n",
    "    result = []\n",
    "\n",
    "    grouped = df.groupby(['video', 'frame'])\n",
    "\n",
    "    for (infant_id, frame_id), group in grouped:\n",
    "        # Check if keypoint 55 is present\n",
    "        if group[group['part_idx'] == 54].empty:\n",
    "            continue\n",
    "\n",
    "        points = list(zip(group['x'], group['y']))\n",
    "        rotation_center = points[54]  # Rotating around the origin\n",
    "\n",
    "        # Find the angle to align the first two points with the horizontal axis\n",
    "        alignment_angle = find_alignment_angle([points[70], points[75]])\n",
    "        # print(f\"Angle to align points with the horizontal axis: {alignment_angle} degrees\")\n",
    "\n",
    "        # Rotate the points using the alignment angle\n",
    "        rotated = rotate_coordinates(points, rotation_center, alignment_angle)\n",
    "        scaled = scale_coordinates(rotated)\n",
    "    \n",
    "\n",
    "        result.append(scaled)\n",
    "        \n",
    "    # Combine results and save to CSV\n",
    "    if not result:\n",
    "        print(\"No frames were processed. Check input data.\")\n",
    "        return\n",
    "    \n",
    "    return pd.DataFrame(list(itertools.chain(*result)), columns=['x', 'y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth and interpolate the data\n",
    "\n",
    "def process_dataframe(file):\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(pose_estimate_path, file))\n",
    "    df.rename(columns={'file_number': 'video_number', 'fname': 'video', 'frame_id': 'frame'}, inplace=True)\n",
    "\n",
    "    if df.empty:\n",
    "        #print(\"DataFrame is empty, skipping processing.\")\n",
    "        return\n",
    "    # print(f\"Processing DataFrame for video_number: {df['video_number'].iloc[0]}\")\n",
    "    \n",
    "    try:\n",
    "        session = df['video'].unique()[0].split('_')[1]\n",
    "        infant = df['video'].unique()[0].split('_')[0]\n",
    "        age = df['video'].unique()[0].split('_')[2]\n",
    "        \n",
    "        print(f'infant: {infant} {session} {age}')\n",
    "\n",
    "        norm = move_and_rotate_keypoints_updated(df)\n",
    "\n",
    "        df['x'] = norm['x']\n",
    "        df['y'] = norm['y']\n",
    "        \n",
    "        # shift each frame to its center \n",
    "        # df['x'] = df['x'] - df.groupby('frame')['x'].transform(\n",
    "        #     lambda x: x.loc[df.loc[x.index, 'part_idx'] == 54].values[0]\n",
    "        #     )\n",
    "        df['x'] = df['x'] - df.groupby('frame')['x'].transform('min')\n",
    "\n",
    "        \n",
    "        median_window = 1\n",
    "        mean_window = 1\n",
    "        delta_window = 0.25  # Smoothing applied to delta_x, velocity, acceleration\n",
    "\n",
    "        df['x'] = pd.to_numeric(df['x'])\n",
    "        df['y'] = pd.to_numeric(df['y'])\n",
    "\n",
    "        # Interpolate\n",
    "        df = df.groupby(['video', 'part_idx']).apply(interpolate_df).reset_index(drop=True)\n",
    "        # Median and mean filter\n",
    "        median_window = 0.5\n",
    "        mean_window = 0.5\n",
    "\n",
    "        df = df.groupby(['video', 'part_idx']).apply(lambda x: smooth(x, 'y', median_window, mean_window)).reset_index(drop=True)\n",
    "        df = df.groupby(['video', 'part_idx']).apply(lambda x: smooth(x, 'x', median_window, mean_window)).reset_index(drop=True)\n",
    "        \n",
    "\n",
    "        df.to_csv(f'{pose_estimate_path}/smooth/{infant}_{session}_{age}_smooth_pose_estimates_coords.csv')\n",
    "        \n",
    "    except:\n",
    "        f'could not process video {df[\"video\"].unique()[0]}'\n",
    "        return\n",
    "        # Rotate and normalize the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth detections and compute features\n",
    "pose_estimate_path = f'./pose_estimates/{dataset}_norm'\n",
    "csv_path = f'{pose_estimate_path}/pose_estimates_{dataset}.csv'\n",
    "save_path = f'{pose_estimate_path}/pose_estimates_{dataset}_processed.csv'\n",
    "\n",
    "# List of subdirectories to create\n",
    "subdirs = [\n",
    "    \"\",\n",
    "    \"xdf\",\n",
    "    \"adf\",\n",
    "    \"xy_features\",\n",
    "    \"angle_features\",\n",
    "    \"xy_features/total\",\n",
    "    \"angle_features/total\",\n",
    "    \"xy_features/windows\",\n",
    "    \"angle_features/windows\",\n",
    "    \"smooth\",\n",
    "    \"symmetrical\",\n",
    "    \"anim\"\n",
    "]\n",
    "\n",
    "# Create necessary directories\n",
    "for subdir in subdirs:\n",
    "    os.makedirs(f'{pose_estimate_path}/{subdir}', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_files = os.listdir(f'{pose_estimate_path}')\n",
    "faces_files = [file for file in faces_files if file.endswith('.csv')]\n",
    "\n",
    "#process only files that havent been processed\n",
    "output_names = os.listdir(f'{pose_estimate_path}/smooth')\n",
    "output_names = [file for file in output_names if file.endswith('.csv')]\n",
    "\n",
    "match = []\n",
    "for name in output_names:\n",
    "    parts = name.split('_')\n",
    "    match.append(f'{parts[0]}_{parts[1]}_{parts[2]}.csv')\n",
    "\n",
    "faces_files = [file for file in faces_files if file not in match]\n",
    "print(f'processing {len(faces_files)} files')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=20) as pool:\n",
    "    pool.map(process_dataframe, faces_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "def init_animation(scatter, text):\n",
    "    \"\"\"Initialization function for the animation.\"\"\"\n",
    "    scatter.set_offsets(np.empty((0, 2)))  # Empty 2D array with shape (0, 2)\n",
    "    text.set_text('')\n",
    "    return scatter, text\n",
    "\n",
    "def update_animation(frame, df, scatter, text):\n",
    "    \"\"\"Update function for the animation.\"\"\"\n",
    "    # Filter data for the current frame\n",
    "    current_frame_data = df[df['frame'] == frame]\n",
    "    \n",
    "    # Ensure we get a 2D array for coordinates\n",
    "    if not current_frame_data.empty:        \n",
    "        coordinates = current_frame_data[['x', 'y']].values\n",
    "    else:\n",
    "        coordinates = np.empty((0, 2))  # Empty 2D array with shape (0, 2)\n",
    "\n",
    "\n",
    "    # Update scatter plot and frame number text\n",
    "    scatter.set_offsets(coordinates)\n",
    "    text.set_text(f\"Frame: {frame}\")\n",
    "    return scatter, text\n",
    "\n",
    "def animate_coordinates(file_path, output_gif=None):\n",
    "    \"\"\"\n",
    "    Animates the time series of (x, y) coordinates from a normalized, rotated file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the normalized and rotated CSV file.\n",
    "    - output_gif (str, optional): Path to save the animation as a GIF file. If None, displays the animation.\n",
    "    \"\"\"\n",
    "    # Load the normalized and rotated file\n",
    "    df = pd.read_csv(file_path)\n",
    "    try:\n",
    "        df.rename(columns={'file_number': 'video_number', 'fname': 'video', 'frame_id': 'frame'}, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    # Ensure required columns exist\n",
    "    required_columns = ['frame', 'x', 'y', 'bp']\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(\"Input CSV is missing required columns: 'frame', 'x', 'y', 'bp'\")\n",
    "\n",
    "    # Sort the data by frame_id\n",
    "    df = df.sort_values(by='frame')\n",
    "    #xlim = df['pixel_x'].unique()[0]\n",
    "    #ylim = df['pixel_y'].unique()[0]\n",
    "\n",
    "    # Extract unique frame IDs and body parts\n",
    "    frame_ids = df['frame'].unique()\n",
    "\n",
    "    # Initialize the figure\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.set_xlim(0, 2.4)  # Normalized range [-1, 1] with padding\n",
    "    ax.set_ylim(0, 1.2)\n",
    "    #ax.set_xlim(0, 10) \n",
    "    #ax.set_ylim(ylim, 0)\n",
    "\n",
    "    ax.set_title(\"Time Series of Keypoints\")\n",
    "    ax.set_xlabel(\"Normalized X\")\n",
    "    ax.set_ylabel(\"Normalized Y\")\n",
    "\n",
    "    # Initialize scatter plot and text\n",
    "    scatter = ax.scatter([], [], s=50, color='blue')  # Placeholder for keypoints\n",
    "    text = ax.text(0, 1, '', fontsize=12)\n",
    "\n",
    "    print(f'starting animation process')\n",
    "    # Create the animation\n",
    "    ani = FuncAnimation(\n",
    "        fig, \n",
    "        update_animation, \n",
    "        frames=frame_ids, \n",
    "        init_func=lambda: init_animation(scatter, text), \n",
    "        fargs=(df, scatter, text), \n",
    "        blit=True, \n",
    "        repeat=True\n",
    "    )\n",
    "    \n",
    "    # Save as GIF or display\n",
    "    if output_gif:\n",
    "        ani.save(output_gif, writer='pillow', fps=10)\n",
    "        print(f\"Animation saved to {output_gif}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def animate_face(file):\n",
    "    input_file = f'{pose_estimate_path}/symmetrical/{file}'\n",
    "    output_gif = f'{pose_estimate_path}/anim/{os.path.splitext(file)[0]}.gif'\n",
    "    animate_coordinates(input_file, output_gif=output_gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "smooth_files = os.listdir(f'{pose_estimate_path}/smooth')\n",
    "smooth_files = random.sample(smooth_files, 5)\n",
    "\n",
    "with Pool(processes=5) as pool:\n",
    "    pool.map(animate_face, smooth_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data \n",
    "\n",
    "# Define midline indices and symmetry pairs\n",
    "midline_index = [54, 53, 52]\n",
    "symmetry_pairs = [(30, 4), (8, 27), (12, 22)]\n",
    "symmetry_threshold = 0.3 #smaller is more strict\n",
    "\n",
    "# Function to compute symmetry score for a single frame\n",
    "def compute_symmetry_score(frame_df):\n",
    "    # Compute the midline X-coordinate\n",
    "    mid_x = frame_df.loc[frame_df['part_idx'].isin(midline_index), 'x'].mean()\n",
    "    \n",
    "    try:\n",
    "    # Calculate symmetry differences\n",
    "        symmetry_diffs = [\n",
    "            abs(abs(frame_df.loc[frame_df['part_idx'] == left, 'x'].values[0] - mid_x) -\n",
    "                abs(frame_df.loc[frame_df['part_idx'] == right, 'x'].values[0] - mid_x))\n",
    "            for left, right in symmetry_pairs\n",
    "        ]\n",
    "        # Compute average symmetry score\n",
    "    except:\n",
    "        symmetry_diffs = np.nan\n",
    "        \n",
    "    return np.mean(symmetry_diffs)\n",
    "\n",
    "def get_symmetrical_frames(df):\n",
    "    scores = (\n",
    "        df.groupby('frame')\n",
    "        .apply(lambda frame_df: compute_symmetry_score(frame_df))\n",
    "        .reset_index(name='symmetry_score')\n",
    "    )\n",
    "    return scores\n",
    "\n",
    "def filter_dataframe(file):\n",
    "    df = pd.read_csv(f'{pose_estimate_path}/smooth/{file}')\n",
    "    scores = get_symmetrical_frames(df)\n",
    "    frames = scores[scores['symmetry_score'] < symmetry_threshold]['frame']\n",
    "    df = df[df['frame'].isin(frames)]\n",
    "    \n",
    "    df.to_csv(f'{pose_estimate_path}/symmetrical/{file}', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 168 files\n"
     ]
    }
   ],
   "source": [
    "# Group by 'frame' and compute symmetry scores\n",
    "smooth_files = os.listdir(f'{pose_estimate_path}/smooth')\n",
    "smooth_files = [file for file in smooth_files if file.endswith('.csv')]\n",
    "\n",
    "output_names = os.listdir(f'{pose_estimate_path}/symmetrical')\n",
    "output_names = [file for file in output_names if file.endswith('.csv')]\n",
    "\n",
    "# match = []\n",
    "# for name in output_names:\n",
    "#     parts = name.split('_')\n",
    "#     match.append(f'{parts[0]}_{parts[1]}_{parts[2]}.csv')\n",
    "\n",
    "smooth_files = [file for file in smooth_files if file not in output_names]\n",
    "print(f'processing {len(smooth_files)} files')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=10) as pool:\n",
    "    pool.map(filter_dataframe, smooth_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute facial features \n",
    "kp_mapping2 ={\n",
    "        **{i: \"upper_brow\" for i in [33,34,35,36,42,43,44,45,46]},\n",
    "        **{i: \"lower_brow\" for i in [47,48,49,50,38,39,40,41]},\n",
    "        **{i: \"upper_eyelid\" for i in [66,67,68,69,70,75,76,77,78,79]},\n",
    "        **{i: \"lower_eyelid\" for i in [71,72,73,80,81,82]},\n",
    "        **{i: \"upper_lip\" for i in [84,85,86,87,88,89,90,99,98,97,96]},\n",
    "        **{i: \"lower_lip\" for i in [103,102,101,91,92,93,94,95]},\n",
    "    }\n",
    "\n",
    "feature_list = ['mean_eyelid_dist',\n",
    "                'mean_lip_dist',\n",
    "                'mean_brow_height',\n",
    "                'mean_brow_curvature',\n",
    "                'mean_eyelid_curvature',\n",
    "                'mean_lip_curvature'\n",
    "                ]     \n",
    "\n",
    "def get_y_distance(df):\n",
    "    return(df[df.upper_lower == 'upper_eyelid'].y.max() - df[df.upper_lower == 'lower_eyelid'].y.min())\n",
    "\n",
    "\n",
    "def get_mean_curvature(points):\n",
    "    return np.mean([CS.circ_std(np.array(points), high=math.pi, low=-math.pi) for points in points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{pose_estimate_path}/smooth/{smooth_files[20]}')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "face = df[df.frame == 17]\n",
    "plt.scatter(face.x, face.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04909447506659975\n"
     ]
    }
   ],
   "source": [
    "r_eye_opening = face[face.bp == 'Right_Eye'].y.max() - face[face.bp == 'Right_Eye'].y.min()\n",
    "l_eye_opening = face[face.bp == 'Left_Eye'].y.max() - face[face.bp == 'Left_Eye'].y.min()\n",
    "\n",
    "print(np.mean([r_eye_opening, l_eye_opening]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict_gma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
