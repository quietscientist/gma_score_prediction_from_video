{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngtR6tOyIFM-",
    "outputId": "12e32194-6ae4-45c0-f4e5-3e1a3d8c66f8"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.makedirs('./data',exist_ok=True)\n",
    "os.makedirs('./utils',exist_ok=True)\n",
    "\n",
    "#download custom processing scripts if not already downloaded\n",
    "# !wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/kinematics.py\n",
    "# !wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/circstat.py\n",
    "# !wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/processing.py\n",
    "# !wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/skeleton.py\n",
    "\n",
    "#download example data or upload your own json annotations\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# Download example raw data from figshare or specify path to your own json annotations |\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "#!wget -P . https://figshare.com/ndownloader/articles/25316500/versions/1\n",
    "# #unzip data into ./data folder and remove zip file\n",
    "# !unzip ./1 -d ./data\n",
    "# !rm ./1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pjaLpviIFNA",
    "outputId": "25749e58-269a-48d4-aa72-667fc737ce05"
   },
   "outputs": [],
   "source": [
    "#uncomment install if running on google colab\n",
    "#%pip install scikit-video\n",
    "\n",
    "import sys, os, cv2, glob, json, gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from itertools import chain\n",
    "from moviepy.editor import VideoFileClip\n",
    "import skvideo.io\n",
    "from tqdm import tqdm\n",
    "import circstat as CS\n",
    "import scipy as sc\n",
    "import math\n",
    "\n",
    "from processing import *\n",
    "from kinematics import *\n",
    "from skeleton import *\n",
    "\n",
    "DEIDENTIFY = True #set to True to deidentify data, and exclude xy coordinates and pixel values from output\n",
    "OVERWRITE = True\n",
    "USE_CENTER_INSTANCE = False\n",
    "USE_BEST_INSTANCE = True\n",
    "\n",
    "dataset = 'gma_score_prediction'\n",
    "json_path = f'./data/Infant Pose Data/{dataset}/annotations'\n",
    "json_files = os.listdir(json_path)\n",
    "directory = f'./data'\n",
    "\n",
    "save_path = f'./pose_estimates/{dataset}_norm'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "kp_mapping = {0:'Nose', 1:'Neck', 2:'RShoulder', 3:'RElbow', 4:'RWrist', 5:'LShoulder', 6:'LElbow',\n",
    "              7:'LWrist', 8:'RHip', 9:'RKnee', 10:'RAnkle', 11:'LHip',\n",
    "              12:'LKnee', 13:'LAnkle', 14:'REye', 15:'LEye', 16:'REar', 17:'LEar'}\n",
    "\n",
    "# Define the DataFrame columns as specified\n",
    "columns = ['video_number', 'video', 'bp', 'frame', 'x', 'y', 'c','fps', 'pixel_x', 'pixel_y', 'time', 'part_idx']\n",
    "data = []  # This will hold the data to be loaded into the DataFrame\n",
    "\n",
    "vid_info = pd.read_csv(f'./data/{dataset}_video_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQ7Dz7hYfoAg",
    "outputId": "dd4ea572-f5c7-4660-b7d2-f07381427692"
   },
   "outputs": [],
   "source": [
    "# format files as pkl with openpose standard and bodypart labels\n",
    "for file_number, file in enumerate(tqdm(json_files)):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(json_path, file)\n",
    "    fname = file.split('.')[0]\n",
    "    interim = []\n",
    "\n",
    "    if not OVERWRITE and os.path.exists(f'{save_path}/{fname}.pkl'):\n",
    "        continue\n",
    "\n",
    "    # Open and load the JSON data\n",
    "    with open(file_path, 'r') as f:\n",
    "        frames = json.load(f)\n",
    "        info = vid_info[vid_info['video'] == fname]\n",
    "        fps = vid_info['fps'].values[0]\n",
    "\n",
    "        pixel_x = vid_info['width'].values[0]\n",
    "        pixel_y = vid_info['height'].values[0]\n",
    "        \n",
    "        center_x = pixel_x / 2\n",
    "        center_y = pixel_y / 2\n",
    "        \n",
    "        # Iterate through each frame in the JSON file\n",
    "        for frame in frames:\n",
    "            frame_id = frame['frame_id']\n",
    "            if 'instances' in frame and len(frame['instances']) > 0:\n",
    "\n",
    "                if USE_CENTER_INSTANCE:\n",
    "                    instance_id = get_center_instance(frame['instances'], center_x, center_y)\n",
    "                elif USE_BEST_INSTANCE:\n",
    "                    instance_id = get_best_instance(frame['instances'])\n",
    "                else:\n",
    "                    instance_id = 0\n",
    "\n",
    "                keypoints = frame['instances'][instance_id]['keypoints']\n",
    "                confidence = frame['instances'][instance_id]['keypoint_scores']\n",
    "                keypoints, confidence = convert_coco_to_openpose(keypoints, confidence)\n",
    "\n",
    "                # Iterate through each keypoint\n",
    "                for part_idx, (x, y) in enumerate(keypoints):\n",
    "\n",
    "                    bp = kp_mapping[part_idx]\n",
    "                    fps = fps\n",
    "                    time = frame_id / fps\n",
    "                    c = confidence[part_idx]\n",
    "\n",
    "                    row = [file_number, fname, bp, frame_id, x, y, c, fps, pixel_x, pixel_y, time, part_idx]\n",
    "                    interim.append(row)\n",
    "\n",
    "    interim_df = pd.DataFrame(interim, columns=columns)\n",
    "    interim_df.to_pickle(f'{save_path}/{fname}.pkl')\n",
    "\n",
    "    del interim_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gF9SA7KO1jbQ",
    "outputId": "0f87b278-d65f-4fba-9149-bd36844f6390"
   },
   "outputs": [],
   "source": [
    "# Ensure the save_path directory exists\n",
    "save_path = f'./pose_estimates/{dataset}_norm'\n",
    "\n",
    "if os.path.exists(f'{save_path}/pose_estimates_{dataset}.csv'):\n",
    "    os.remove(f'{save_path}/pose_estimates_{dataset}.csv')\n",
    "    print('Removed existing CSV file')\n",
    "\n",
    "for pklfile in tqdm(os.listdir(save_path)):\n",
    "    if not pklfile.endswith('.pkl'):\n",
    "        continue\n",
    "    else:\n",
    "        interim_df = pd.read_pickle(f'{save_path}/{pklfile}')\n",
    "        interim_df.to_csv(f'{save_path}/pose_estimates_{dataset}.csv', mode='a', header=False, index=False)\n",
    "\n",
    "    del interim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERK1DQ-92DsG"
   },
   "outputs": [],
   "source": [
    "csv_path = f'{save_path}/pose_estimates_{dataset}.csv'\n",
    "output_csv_path = f'{save_path}/pose_estimates_{dataset}_b.csv'\n",
    "chunksize = 1000  # Number of rows per chunk\n",
    "\n",
    "# Define the new headers\n",
    "new_headers = ['video_number', 'video', 'bp', 'frame', 'x', 'y', 'c', 'fps', 'pixel_x', 'pixel_y', 'time', 'part_idx']\n",
    "\n",
    "# Read the CSV file in chunks\n",
    "chunk_iterator = pd.read_csv(csv_path, chunksize=chunksize)\n",
    "\n",
    "# Process the first chunk\n",
    "first_chunk = next(chunk_iterator)\n",
    "first_chunk.columns = new_headers\n",
    "first_chunk.to_csv(output_csv_path, mode='w', index=False)\n",
    "\n",
    "# Process the rest of the chunks and append them to the new CSV file without headers\n",
    "for chunk in chunk_iterator:\n",
    "    chunk.columns = new_headers\n",
    "    chunk.to_csv(output_csv_path, mode='a', index=False, header=False)\n",
    "\n",
    "# rename the csv file\n",
    "os.rename(csv_path, f'{save_path}/pose_estimates_{dataset}_x.csv')\n",
    "os.rename(output_csv_path, csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5A-LkovEMav"
   },
   "outputs": [],
   "source": [
    "def process_dataframe(df, pose_estimate_path):\n",
    "    if df.empty:\n",
    "        #print(\"DataFrame is empty, skipping processing.\")\n",
    "        return\n",
    "    print(f\"Processing DataFrame for video_number: {df['video_number'].iloc[0]}\")\n",
    "    try:\n",
    "        if dataset == 'Youtube':\n",
    "            session = df['video'].unique()[0].split('_')[1][0]\n",
    "            infant = df['video'].unique()[0].split('_')[1][3:]\n",
    "        elif dataset == 'Clinical':\n",
    "            # split based on naming convention\n",
    "            session = df['video'].unique()[0].split('_')[1][1]\n",
    "            infant = df['video'].unique()[0].split('_')[0][-1]\n",
    "        elif dataset == 'gma_score_prediction': \n",
    "            session = 0\n",
    "            infant = df['video'].unique()[0]\n",
    "\n",
    "        age = '3_4 Month'\n",
    "\n",
    "        print(f'infant: {infant}')\n",
    "        \n",
    "    except:\n",
    "        f'could not process video {df[\"video\"].unique()[0]}'\n",
    "        return\n",
    "\n",
    "    median_window = 1\n",
    "    mean_window = 1\n",
    "    delta_window = 0.25  # Smoothing applied to delta_x, velocity, acceleration\n",
    "\n",
    "    df['x'] = pd.to_numeric(df['x'])\n",
    "    df['y'] = pd.to_numeric(df['y'])\n",
    "\n",
    "    # Interpolate\n",
    "    df = df.groupby(['video', 'bp']).apply(interpolate_df).reset_index(drop=True)\n",
    "\n",
    "    # Median and mean filter\n",
    "    median_window = 0.5\n",
    "    mean_window = 0.5\n",
    "    df = df.groupby(['video', 'bp']).apply(lambda x: smooth(x, 'y', median_window, mean_window)).reset_index(drop=True)\n",
    "    df = df.groupby(['video', 'bp']).apply(lambda x: smooth(x, 'x', median_window, mean_window)).reset_index(drop=True)\n",
    "\n",
    "    try:\n",
    "        # Rotate and normalise by reference\n",
    "        xdf = normalise_skeletons(df)\n",
    "        xdf = get_dynamics_xy(xdf, delta_window)\n",
    "            \n",
    "        xdf.to_pickle(f'{pose_estimate_path}/xdf/{infant}_{session}_processed_pose_estimates_coords_norm.pkl')\n",
    "\n",
    "        adf = get_joint_angles(df)\n",
    "        adf = get_dynamics_angle(adf, delta_window)\n",
    "        adf.to_pickle(f'{pose_estimate_path}/adf/{infant}_{session}_processed_pose_estimates_coords_norm.pkl')\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f'Error processing video for {infant}: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "I4107PvX25fK"
   },
   "outputs": [],
   "source": [
    "# Smooth detections and compute features\n",
    "pose_estimate_path = f'./pose_estimates/{dataset}_norm'\n",
    "csv_path = f'{pose_estimate_path}/pose_estimates_{dataset}.csv'\n",
    "save_path = f'{pose_estimate_path}/pose_estimates_{dataset}_processed.csv'\n",
    "\n",
    "# List of subdirectories to create\n",
    "subdirs = [\n",
    "    \"\",\n",
    "    \"xdf\",\n",
    "    \"adf\",\n",
    "    \"xy_features\",\n",
    "    \"angle_features\",\n",
    "    \"xy_features/total\",\n",
    "    \"angle_features/total\",\n",
    "    \"xy_features/windows\",\n",
    "    \"angle_features/windows\"\n",
    "]\n",
    "\n",
    "# Create necessary directories\n",
    "for subdir in subdirs:\n",
    "    os.makedirs(f'{pose_estimate_path}/{subdir}', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u0ik4gOyCDVZ",
    "outputId": "f16fdcc3-5798-47cc-f78c-282d79d7e7ae"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "chunksize = 100000\n",
    "buffer = pd.DataFrame()\n",
    "\n",
    "# Read the CSV file in chunks\n",
    "chunk_iterator = pd.read_csv(csv_path, chunksize=chunksize)\n",
    "\n",
    "for chunk in chunk_iterator:\n",
    "  unique_videos = chunk['video_number'].unique()\n",
    "\n",
    "  for video_number in unique_videos:\n",
    "      video_chunk = chunk[chunk['video_number'] == video_number]\n",
    "\n",
    "      if not buffer.empty:\n",
    "        if buffer['video_number'].iloc[0] == video_number:\n",
    "\n",
    "            buffer = pd.concat([buffer, video_chunk], ignore_index=True)\n",
    "            if video_number not in chunk['video_number'].values:\n",
    "                process_dataframe(buffer, pose_estimate_path)\n",
    "                buffer = pd.DataFrame()\n",
    "\n",
    "        else:\n",
    "            process_dataframe(buffer, pose_estimate_path)\n",
    "            buffer = video_chunk\n",
    "      else:\n",
    "          buffer = video_chunk\n",
    "  clear_output(wait=True)\n",
    "  chunk = chunk[~chunk['video_number'].isin(unique_videos)]\n",
    "\n",
    "# # Process any remaining rows in the buffer\n",
    "if not buffer.empty:\n",
    "    print(\"Processing remaining rows in the buffer...\")\n",
    "    process_dataframe(buffer, pose_estimate_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AenvmNmB3cc5",
    "outputId": "7925b160-4c5f-45f2-fe96-c02775cf3106"
   },
   "outputs": [],
   "source": [
    "#compute xy features\n",
    "\n",
    "def process_xdf_file(file): \n",
    "        if 'pkl' in file:\n",
    "             xdf = pd.read_pickle(os.path.join(f'{pose_estimate_path}/xdf', file))\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "        bps = ['LAnkle', 'RAnkle', 'LWrist', 'RWrist']\n",
    "        filtered_xdf = xdf[np.isin(xdf.bp, bps)]\n",
    "        video_number = xdf.video.unique()[0]\n",
    "        \n",
    "        # Compute window xy features: \n",
    "        mean_type = 'windows'\n",
    "        feature_xy = xdf.groupby(['bp', 'video']).apply(lambda group: rolling_xy_features(group, window_size=60)).reset_index(drop=True)\n",
    "        feature_xy = pd.pivot_table(feature_xy, index=['video','frame'], columns=['bp'])\n",
    "           \n",
    "        l0 = feature_xy.columns.get_level_values(1)\n",
    "        l1 = feature_xy.columns.get_level_values(0)\n",
    "\n",
    "        cols = [l1[i]+'_'+l0[i] for i in range(len(l1))]\n",
    "        feature_xy.columns = cols\n",
    "        feature_xy = feature_xy.reset_index()\n",
    "\n",
    "        # - measure of symmetry (left-right cross correlation)\n",
    "        xdf['dist'] = np.sqrt(xdf['x']**2+xdf['y']**2)\n",
    "        corr_joint = xdf[np.isin(xdf.bp, bps)].groupby(['video', 'part']).apply(lambda x:rolling_corr_lr(x,var='dist')).reset_index()\n",
    "        corr_joint['part'] = 'lrCorr_x_'+corr_joint['part']\n",
    "        corr_joint.drop(columns=['level_2','R','L'],inplace=True)\n",
    "\n",
    "        corr_joint.columns = ['video', 'feature', 'frame', 'Value']\n",
    "        corr_joint = pd.pivot_table(corr_joint, index=['video', 'frame'], columns=['feature'])\n",
    "        l1 = corr_joint.columns.get_level_values(1)\n",
    "        corr_joint.columns = l1\n",
    "        corr_joint = corr_joint.reset_index()\n",
    "        feature_xy = pd.merge(feature_xy, corr_joint, on=['video','frame'], how='outer')\n",
    "\n",
    "        feature_xy.to_csv(f'{pose_estimate_path}/xy_features/{mean_type}/{video_number}_features_{mean_type}_xy.csv', header=True, index=False)\n",
    "    \n",
    "        #compute total xy features (average by video)\n",
    "        mean_type = 'total'\n",
    "\n",
    "        feature_xy = filtered_xdf.groupby(['bp','video']).apply(xy_features).reset_index(drop=True)\n",
    "        feature_xy = pd.pivot_table(feature_xy, index='video', columns=['bp'])\n",
    "        l0 = feature_xy.columns.get_level_values(1)\n",
    "        l1 = feature_xy.columns.get_level_values(0)\n",
    "        cols = [l1[i]+'_'+l0[i] for i in range(len(l1))]\n",
    "        feature_xy.columns = cols\n",
    "        feature_xy = feature_xy.reset_index()\n",
    "\n",
    "        # - measure of symmetry (left-right cross correlation)\n",
    "\n",
    "        xdf['dist'] = np.sqrt(xdf['x']**2+xdf['y']**2)\n",
    "        corr_joint = xdf.groupby(['video', 'part']).apply(lambda x:corr_lr(x,'dist')).reset_index()\n",
    "        corr_joint['part'] = 'lrCorr_x_'+corr_joint['part']\n",
    "        corr_joint.columns = ['video', 'feature', 'Value']\n",
    "        corr_joint = pd.pivot_table(corr_joint, index='video', columns=['feature'])\n",
    "        l1 = corr_joint.columns.get_level_values(1)\n",
    "        corr_joint.columns = l1\n",
    "        corr_joint = corr_joint.reset_index()\n",
    "        feature_xy = pd.merge(feature_xy, corr_joint, on='video', how='outer')\n",
    "        \n",
    "        feature_xy.to_csv(f'{pose_estimate_path}/xy_features/{mean_type}/{video_number}_features_{mean_type}_xy.csv', header=True, index=False)\n",
    "\n",
    "        return\n",
    "\n",
    "# Compute angular features\n",
    "\n",
    "def process_adf_file(file): \n",
    "        if 'pkl' in file:\n",
    "             adf = pd.read_pickle(os.path.join(f'{pose_estimate_path}/adf', file))\n",
    "        else:\n",
    "            return       \n",
    "\n",
    "        video_number = adf.video.unique()[0]\n",
    "\n",
    "        # Compute window angle features: \n",
    "        mean_type = 'windows'\n",
    "        window_size = 2*int(adf['fps'].iloc[0]) # 2 seconds\n",
    "\n",
    "        # Compute window angle features: \n",
    "        feature_angle = adf.groupby(['bp','video']).apply(rolling_angle_features, window_size=window_size).reset_index(drop=True)\n",
    "        feature_angle = pd.pivot_table(feature_angle, index=['video','frame'], columns=['bp'])\n",
    "        l0 = feature_angle.columns.get_level_values(1)\n",
    "        l1 = feature_angle.columns.get_level_values(0)\n",
    "        cols = [l1[i]+'_'+l0[i] for i in range(len(l1))]\n",
    "        feature_angle.columns = cols\n",
    "        feature_angle =feature_angle.reset_index()\n",
    "\n",
    "        # - measure of symmetry (left-right cross correlation)\n",
    "        corr_joint = adf.groupby(['video', 'part']).apply(rolling_core_lr, window_size=window_size, min_periods=1, var='angle')\n",
    "        corr_joint.reset_index(inplace=True)\n",
    "        corr_joint.drop(columns=['level_2','R','L'],inplace=True)\n",
    "        corr_joint['part'] = 'lrCorr_angle_'+corr_joint['part']\n",
    "        corr_joint.columns = ['video', 'feature', 'frame','Value']\n",
    "        corr_joint = pd.pivot_table(corr_joint, index=['video','frame'], columns=['feature'])\n",
    "        l1 = corr_joint.columns.get_level_values(1)\n",
    "        corr_joint.columns = l1\n",
    "        corr_joint = corr_joint.reset_index()\n",
    "\n",
    "        feature_angle = pd.merge(feature_angle,corr_joint, on=['video','frame'], how='outer')\n",
    "        feature_angle.to_csv(f'{pose_estimate_path}/angle_features/{mean_type}/{video_number}_features_{mean_type}_angle.csv', header=True, index=False)\n",
    "\n",
    "        #compute total angle features (average by video)\n",
    "        mean_type = 'total'\n",
    "        feature_angle = adf.groupby(['bp','video']).apply(angle_features).reset_index(drop=True)\n",
    "        feature_angle = pd.pivot_table(feature_angle, index='video', columns=['bp'])        \n",
    "        \n",
    "        l0 = feature_angle.columns.get_level_values(1)\n",
    "        l1 = feature_angle.columns.get_level_values(0)\n",
    "        cols = [l1[i]+'_'+l0[i] for i in range(len(l1))]\n",
    "        feature_angle.columns = cols\n",
    "        feature_angle =feature_angle.reset_index()\n",
    "\n",
    "        # - measure of symmetry (left-right cross correlation)\n",
    "        corr_joint = adf.groupby(['video', 'part']).apply(lambda x:corr_lr(x,'angle')).reset_index()\n",
    "        corr_joint['part'] = 'lrCorr_angle_'+corr_joint['part']\n",
    "        corr_joint.columns = ['video', 'feature', 'Value']\n",
    "        corr_joint = pd.pivot_table(corr_joint, index='video', columns=['feature'])\n",
    "        l1 = corr_joint.columns.get_level_values(1)\n",
    "        corr_joint.columns = l1\n",
    "        corr_joint = corr_joint.reset_index()\n",
    "        feature_angle = pd.merge(feature_angle,corr_joint, on='video', how='outer')\n",
    "\n",
    "        feature_angle.to_csv(f'{pose_estimate_path}/angle_features/{mean_type}/{video_number}_features_{mean_type}_angle.csv', header=True, index=False)\n",
    "        \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "pool = multiprocessing.Pool(processes=20)  # Adjust the number of processes as needed\n",
    "file_paths = os.listdir(f'{pose_estimate_path}/xdf')  # List of file paths\n",
    "results = pool.map(process_xdf_file, file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m pool \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)  \u001b[38;5;66;03m# Adjust the number of processes as needed\u001b[39;00m\n\u001b[1;32m      4\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpose_estimate_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/adf\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# List of file paths\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_adf_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda/envs/predict_gma/lib/python3.8/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda/envs/predict_gma/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda/envs/predict_gma/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda/envs/predict_gma/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/miniconda/envs/predict_gma/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "pool = multiprocessing.Pool(processes=20)  # Adjust the number of processes as needed\n",
    "file_paths = os.listdir(f'{pose_estimate_path}/adf')  # List of file paths\n",
    "results = pool.map(process_adf_file, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhWbYFEQ5L8X"
   },
   "outputs": [],
   "source": [
    "# Combine features\n",
    "SAVE = True\n",
    "\n",
    "features_xy = pd.read_csv(f'{pose_estimate_path}/features_xy.csv')\n",
    "features_angle = pd.read_csv(f'{pose_estimate_path}/features_angle.csv')\n",
    "\n",
    "features = pd.merge(features_xy, features_angle, on='video', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fKR50_t6F3n"
   },
   "outputs": [],
   "source": [
    "# Split features based on video file naming convention\n",
    "\n",
    "if dataset == 'Youtube':\n",
    "    features['infant'] = features['video'].str.split('_').str.get(1).str[-3:]\n",
    "    features['session'] = features['video'].str.split('_').str.get(1).str[0]\n",
    "    features['age'] = 'month'\n",
    "\n",
    "elif dataset == 'Clinical':\n",
    "    features['infant'] = features['video'].str.split('_').str.get(0).str[-1]\n",
    "    features['session'] = features['video'].str.split('_').str.get(1).str[1]\n",
    "    features['age'] = 'month'\n",
    "\n",
    "elif dataset == 'gma_score_prediction':\n",
    "    features['infant'] = features['video']\n",
    "    features['session'] = 0\n",
    "    features['age'] = 'month'\n",
    "\n",
    "if SAVE:\n",
    "    features.to_csv(f'{pose_estimate_path}/features.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fw5_xTrfi9tA"
   },
   "outputs": [],
   "source": [
    "# Body parts and sides\n",
    "body_parts = [\"Knee\", \"Shoulder\", \"Hip\", \"Elbow\", \"Wrist\", \"Ankle\"]\n",
    "sides = [\"L\", \"R\"]\n",
    "\n",
    "# Function to split the feature string into \"feature\", \"part\", and \"side\"\n",
    "def split_feature(feature):\n",
    "    # Split the feature into components\n",
    "    parts = feature.split('_')\n",
    "    feature_name = \"_\".join(parts[:-1])  # Default to everything before the last part\n",
    "    part = parts[-1] if len(parts) > 1 else \"\"  # Default to the last part\n",
    "\n",
    "    side = \"\"\n",
    "\n",
    "    # Check if the last part has a side\n",
    "    for body_part in body_parts:\n",
    "        if body_part in part:  # Find body part\n",
    "            idx = part.index(body_part)\n",
    "            if idx > 0 and part[idx-1] in sides:  # Check for side prefix\n",
    "                side = part[idx-1]\n",
    "                part = part[idx:]  # Remove the side from the part\n",
    "            break  # Exit loop after finding the body part\n",
    "\n",
    "    # Adjust feature name to remove body part and side, if found\n",
    "    if part in feature_name:\n",
    "        feature_name = feature_name.replace(part, \"\").strip(\"_\")\n",
    "    if side in feature_name:\n",
    "        feature_name = feature_name.replace(side, \"\").strip(\"_\")\n",
    "\n",
    "    return pd.Series([feature_name, part, side])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Td9C5LWE67Iv",
    "outputId": "732f3a60-77ef-4ccb-a7f9-921c9edc7863"
   },
   "outputs": [],
   "source": [
    "# Include data for the following, and restructure dataframe\n",
    "# Customize for your specific dataset\n",
    "id_vars = ['infant', 'age','session','video']\n",
    "melted = pd.melt(features, id_vars=id_vars, var_name=\"feature\", value_name=\"Value\")\n",
    "\n",
    "# Apply the function to the 'feature' column in your melted DataFrame\n",
    "melted[['feature', 'part', 'side']] = melted['feature'].apply(split_feature)\n",
    "melted = melted.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = melted.groupby(['infant', 'age', 'session', 'video', 'feature', 'part'])['Value'].mean().reset_index()\n",
    "mean.to_csv(f'{pose_estimate_path}/{dataset}_features_mean_by_side.csv', header=True, index=False)\n",
    "\n",
    "mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLCqy4CzZtsZ"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "predict_gma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
