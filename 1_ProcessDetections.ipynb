{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "ngtR6tOyIFM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef4a834-ac2a-4d39-c88f-5359bd48a311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-05 16:53:27--  https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/kinematics.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9865 (9.6K) [text/plain]\n",
            "Saving to: ‘./kinematics.py.1’\n",
            "\n",
            "\rkinematics.py.1       0%[                    ]       0  --.-KB/s               \rkinematics.py.1     100%[===================>]   9.63K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-05 16:53:27 (52.7 MB/s) - ‘./kinematics.py.1’ saved [9865/9865]\n",
            "\n",
            "--2024-12-05 16:53:27--  https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/circstat.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29875 (29K) [text/plain]\n",
            "Saving to: ‘./circstat.py.1’\n",
            "\n",
            "circstat.py.1       100%[===================>]  29.17K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-12-05 16:53:27 (6.58 MB/s) - ‘./circstat.py.1’ saved [29875/29875]\n",
            "\n",
            "--2024-12-05 16:53:27--  https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/processing.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24258 (24K) [text/plain]\n",
            "Saving to: ‘./processing.py.1’\n",
            "\n",
            "processing.py.1     100%[===================>]  23.69K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-12-05 16:53:27 (14.8 MB/s) - ‘./processing.py.1’ saved [24258/24258]\n",
            "\n",
            "--2024-12-05 16:53:28--  https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/skeleton.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1786 (1.7K) [text/plain]\n",
            "Saving to: ‘./skeleton.py.1’\n",
            "\n",
            "skeleton.py.1       100%[===================>]   1.74K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-05 16:53:28 (24.0 MB/s) - ‘./skeleton.py.1’ saved [1786/1786]\n",
            "\n",
            "--2024-12-05 16:53:28--  https://figshare.com/ndownloader/articles/25316500/versions/1\n",
            "Resolving figshare.com (figshare.com)... 34.252.194.191, 108.128.113.175, 2a05:d018:1f4:d000:2ff1:256e:d815:335, ...\n",
            "Connecting to figshare.com (figshare.com)|34.252.194.191|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 826324289 (788M) [application/zip]\n",
            "Saving to: ‘./1’\n",
            "\n",
            "1                   100%[===================>] 788.04M  28.1MB/s    in 31s     \n",
            "\n",
            "2024-12-05 16:54:00 (25.1 MB/s) - ‘./1’ saved [826324289/826324289]\n",
            "\n",
            "Archive:  ./1\n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000073.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000360.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000086.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000340.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000090.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000244.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000141.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000004.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000287.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000290.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000286.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000269.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000140.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000005.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000394.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000052.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000204.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000068.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000398.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000072.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000079.json  \n",
            " extracting: ./data/YT_video_info.csv  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000110.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000405.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000297.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000106.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000385.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000059.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000274.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000366.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000275.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000107.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000412.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000296.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000111.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000295.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000283.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000000.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000112.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000169.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000186.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000352.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000190.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000364.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000276.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000077.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000173.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000172.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000099.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000021.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000236.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000365.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000191.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000353.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000241.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000001.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000282.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000369.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000227.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000071.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000358.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000088.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000047.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000285.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000342.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000179.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000396.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000379.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000284.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000011.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000292.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000031.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000089.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000070.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000267.json  \n",
            " extracting: ./data/Infant Pose Data/Youtube/annotations/video_000288.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-23_1_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-16_1_1_gp1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-11_2_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-24_1_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487_30_2_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-6_1_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-19_2_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-7_1_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-17_1_1_gp1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-18_2_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-9_2_2_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-11_1_2_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-26_1_1_gp1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-8_1_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-7_2_1_gp1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-34_1_1_realsense_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-20_1_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-31_1_1_realsense_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-27_1_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-25_1_gp2_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-30_2_3_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487_6_1_2_gp1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-15_1_1_gp1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-9_2_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487_11_3_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-8_1_2_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487_30_1_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-11_1_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-9_3_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-18_1_1_gp1_1.json  \n",
            " extracting: ./data/Infant Pose Data/Clinical/annotations/822487-11_2_2_gp1_1.json  \n",
            " extracting: ./data/CLIN_video_info.csv  \n"
          ]
        }
      ],
      "source": [
        "#download dependencies\n",
        "!wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/kinematics.py\n",
        "!wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/circstat.py\n",
        "!wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/processing.py\n",
        "!wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/skeleton.py\n",
        "\n",
        "#download example data or upload your own json annotations\n",
        "\n",
        "import os\n",
        "os.makedirs('./data',exist_ok=True)\n",
        "!wget -P . https://figshare.com/ndownloader/articles/25316500/versions/1\n",
        "\n",
        "#unzip data into ./data folder and remove zip file\n",
        "!unzip ./1 -d ./data\n",
        "!rm ./1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "0pjaLpviIFNA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac1ff49-ce50-4533-e50f-d959263c9fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-video\n",
            "  Downloading scikit_video-1.1.11-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from scikit-video) (11.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.13.1)\n",
            "Downloading scikit_video-1.1.11-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%pip install scikit-video\n",
        "\n",
        "import sys, os, cv2, glob, json, gc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from itertools import chain\n",
        "from moviepy.editor import VideoFileClip\n",
        "import skvideo.io\n",
        "from tqdm import tqdm\n",
        "import circstat as CS\n",
        "import scipy as sc\n",
        "import math\n",
        "\n",
        "from processing import *\n",
        "from kinematics import *\n",
        "from skeleton import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# format files as pkl with openpose standard and bodypart labels\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "OVERWRITE = True\n",
        "USE_CENTER_INSTANCE = False\n",
        "USE_BEST_INSTANCE = True\n",
        "\n",
        "dataset = 'Youtube'\n",
        "json_path = f'/content/data/Infant Pose Data/{dataset}/annotations'\n",
        "json_files = os.listdir(json_path)\n",
        "directory = f'./data'\n",
        "\n",
        "save_path = f'./pose_estimates/{dataset}_norm'\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "kp_mapping = {0:'Nose', 1:'Neck', 2:'RShoulder', 3:'RElbow', 4:'RWrist', 5:'LShoulder', 6:'LElbow',\n",
        "              7:'LWrist', 8:'RHip', 9:'RKnee', 10:'RAnkle', 11:'LHip',\n",
        "              12:'LKnee', 13:'LAnkle', 14:'REye', 15:'LEye', 16:'REar', 17:'LEar'}\n",
        "\n",
        "# Define the DataFrame columns as specified\n",
        "columns = ['video_number', 'video', 'bp', 'frame', 'x', 'y', 'c','fps', 'pixel_x', 'pixel_y', 'time', 'part_idx']\n",
        "data = []  # This will hold the data to be loaded into the DataFrame\n",
        "\n",
        "if dataset == 'Youtube':\n",
        "    vid_info = pd.read_csv('/content/data/YT_video_info.csv')\n",
        "elif dataset == 'Clinical':\n",
        "    vid_info = pd.read_csv('/content/data/CLIN_video_info.csv')\n",
        "\n",
        "\n",
        "for file_number, file in enumerate(tqdm(json_files)):\n",
        "    # Construct the full file path\n",
        "    file_path = os.path.join(json_path, file)\n",
        "    fname = file.split('.')[0]\n",
        "    interim = []\n",
        "\n",
        "    if not OVERWRITE and os.path.exists(f'{save_path}/{fname}.pkl'):\n",
        "        continue\n",
        "\n",
        "    # Open and load the JSON data\n",
        "    with open(file_path, 'r') as f:\n",
        "        frames = json.load(f)\n",
        "        info = vid_info[vid_info['video'] == fname]\n",
        "        center_x = info['center_x'].values[0]\n",
        "        center_y = info['center_y'].values[0]\n",
        "        pixel_x = info['width'].values[0]\n",
        "        pixel_y = info['height'].values[0]\n",
        "        fps = info['fps'].values[0]\n",
        "\n",
        "        # Iterate through each frame in the JSON file\n",
        "        for frame in frames:\n",
        "            frame_id = frame['frame_id']\n",
        "            if 'instances' in frame and len(frame['instances']) > 0:\n",
        "\n",
        "                if USE_CENTER_INSTANCE:\n",
        "                    instance_id = get_center_instance(frame['instances'], center_x, center_y)\n",
        "                elif USE_BEST_INSTANCE:\n",
        "                    instance_id = get_best_instance(frame['instances'])\n",
        "                else:\n",
        "                    instance_id = 0\n",
        "\n",
        "                keypoints = frame['instances'][instance_id]['keypoints']\n",
        "                confidence = frame['instances'][instance_id]['keypoint_scores']\n",
        "                keypoints, confidence = convert_coco_to_openpose(keypoints, confidence)\n",
        "\n",
        "                # Iterate through each keypoint\n",
        "                for part_idx, (x, y) in enumerate(keypoints):\n",
        "\n",
        "                    bp = kp_mapping[part_idx]\n",
        "                    fps = fps\n",
        "                    time = frame_id / fps\n",
        "                    c = confidence[part_idx]\n",
        "\n",
        "                    row = [file_number, fname, bp, frame_id, x, y, c, fps, pixel_x, pixel_y, time, part_idx]\n",
        "                    interim.append(row)\n",
        "\n",
        "    interim_df = pd.DataFrame(interim, columns=columns)\n",
        "    interim_df.to_pickle(f'{save_path}/{fname}.pkl')\n",
        "\n",
        "    del interim_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "VQ7Dz7hYfoAg",
        "outputId": "6f3d59f3-b8f1-4b4c-9171-6b5aedf9d48d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './data/video_info.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3f344cd01d3b>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'video_number'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'video'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fps'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pixel_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pixel_y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'part_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# This will hold the data to be loaded into the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mvid_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/video_info.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/video_info.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for pklfile in tqdm(os.listdir(save_path)):\n",
        "\n",
        "    interim_df = pd.read_pickle(f'{save_path}/{pklfile}')\n",
        "    interim_df.to_csv(f'{save_path}/pose_estimates_{dataset}.csv', mode='a', header=False, index=False)\n",
        "\n",
        "    del interim_df"
      ],
      "metadata": {
        "id": "gF9SA7KO1jbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'YT'\n",
        "\n",
        "csv_path = f'{save_path}/pose_estimates_{dataset}.csv'\n",
        "output_csv_path = f'{save_path}/pose_estimates_{dataset}_b.csv'\n",
        "chunksize = 1000  # Number of rows per chunk\n",
        "\n",
        "# Define the new headers\n",
        "new_headers = ['video_number', 'video', 'bp', 'frame', 'x', 'y', 'c', 'fps', 'pixel_x', 'pixel_y', 'time', 'part_idx']\n",
        "\n",
        "# Read the CSV file in chunks\n",
        "chunk_iterator = pd.read_csv(csv_path, chunksize=chunksize)\n",
        "\n",
        "# Process the first chunk\n",
        "first_chunk = next(chunk_iterator)\n",
        "first_chunk.columns = new_headers\n",
        "first_chunk.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# Process the rest of the chunks and append them to the new CSV file without headers\n",
        "for chunk in chunk_iterator:\n",
        "    chunk.columns = new_headers\n",
        "    chunk.to_csv(output_csv_path, mode='a', index=False, header=False)\n",
        "\n",
        "# rename the csv file\n",
        "os.rename(csv_path, f'{save_path}pose_estimates_{dataset}_x.csv')\n",
        "os.rename(output_csv_path, csv_path)\n",
        "\n",
        "#remove other files\n",
        "os.remove(f'{save_path}/pose_estimates_{dataset}_b.csv')\n",
        "os.remove(f'{save_path}/pose_estimates_{dataset}_x.csv')"
      ],
      "metadata": {
        "id": "ERK1DQ-92DsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Smooth detections and compute features\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs(pose_estimate_path, exist_ok=True)\n",
        "os.makedirs(f'{pose_estimate_path}/xdf', exist_ok=True)\n",
        "os.makedirs(f'{pose_estimate_path}/adf', exist_ok=True)\n",
        "\n",
        "chunksize = 100000\n",
        "buffer = pd.DataFrame()\n",
        "\n",
        "# Read the CSV file in chunks\n",
        "chunk_iterator = pd.read_csv(csv_path, chunksize=chunksize)\n",
        "\n",
        "def process_dataframe(df, pose_estimate_path):\n",
        "    if df.empty:\n",
        "        print(\"DataFrame is empty, skipping processing.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Processing DataFrame for video_number: {df['video_number'].iloc[0]}\")\n",
        "    if 'PANDA2B' in dataset:\n",
        "        session = df['video'].unique()[0].split('_')[1]\n",
        "        infant = df['video'].unique()[0].split('_')[0]\n",
        "        age = df['video'].unique()[0].split('_')[-2]\n",
        "    if 'NERDS' in dataset:\n",
        "        #session = df['video'].unique()[0].split('_')[1][0:3]\n",
        "        #infant = df['video'].unique()[0].split('_')[1][3:6]\n",
        "        session = df['video'].unique()[0].split('_')[0]\n",
        "        infant = df['video'].unique()[0].split('_')[-1]\n",
        "    else:\n",
        "        try:\n",
        "            session = ''.join(df['video'].unique()[0].split('_')[1:4])\n",
        "            infant = df['video'].unique()[0].split('_')[-3]\n",
        "            age = 'month'\n",
        "        except:\n",
        "            f'could not process video {df[\"video\"].unique()[0]}'\n",
        "            return\n",
        "\n",
        "    median_window = 1\n",
        "    mean_window = 1\n",
        "    delta_window = 0.25  # Smoothing applied to delta_x, velocity, acceleration\n",
        "\n",
        "    df['x'] = pd.to_numeric(df['x'])\n",
        "    df['y'] = pd.to_numeric(df['y'])\n",
        "\n",
        "    # Interpolate\n",
        "    df = df.groupby(['video', 'bp']).apply(interpolate_df).reset_index(drop=True)\n",
        "\n",
        "    # Median and mean filter\n",
        "    median_window = 0.5\n",
        "    mean_window = 0.5\n",
        "    df = df.groupby(['video', 'bp']).apply(lambda x: smooth(x, 'y', median_window, mean_window)).reset_index(drop=True)\n",
        "    df = df.groupby(['video', 'bp']).apply(lambda x: smooth(x, 'x', median_window, mean_window)).reset_index(drop=True)\n",
        "\n",
        "    try:\n",
        "        # Rotate and normalise by reference\n",
        "        ##xdf = dont_normalise_skeletons(df)\n",
        "        xdf = normalise_skeletons(df)\n",
        "        xdf = get_dynamics_xy(xdf, delta_window)\n",
        "        xdf.to_pickle(f'{pose_estimate_path}/xdf/{infant}_{session}_processed_pose_estimates_coords_norm.pkl')\n",
        "\n",
        "        adf = get_joint_angles(df)\n",
        "        adf = get_dynamics_angle(adf, delta_window)\n",
        "        adf.to_pickle(f'{pose_estimate_path}/adf/{infant}_{session}_processed_pose_estimates_coords_norm.pkl')\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f'Error processing video for {infant}: {e}')\n",
        "\n",
        "for chunk in chunk_iterator:\n",
        "    print(\"Processing new chunk\")\n",
        "    unique_videos = chunk['video_number'].unique()\n",
        "    print(f\"Unique video_numbers in chunk: {unique_videos}\")\n",
        "\n",
        "    for video_number in unique_videos:\n",
        "        video_chunk = chunk[chunk['video_number'] == video_number]\n",
        "\n",
        "        if not buffer.empty:\n",
        "            if buffer['video_number'].iloc[0] == video_number:\n",
        "                buffer = pd.concat([buffer, video_chunk], ignore_index=True)\n",
        "                if video_number not in chunk['video_number'].values:\n",
        "                    process_dataframe(buffer, pose_estimate_path)\n",
        "                    buffer = pd.DataFrame()\n",
        "            else:\n",
        "                process_dataframe(buffer, pose_estimate_path)\n",
        "                buffer = video_chunk\n",
        "        else:\n",
        "            buffer = video_chunk\n",
        "\n",
        "    chunk = chunk[~chunk['video_number'].isin(unique_videos)]\n",
        "\n",
        "# Process any remaining rows in the buffer\n",
        "if not buffer.empty:\n",
        "    print(\"Processing remaining rows in the buffer...\")\n",
        "    process_dataframe(buffer, pose_estimate_path)"
      ],
      "metadata": {
        "id": "I4107PvX25fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute angular features\n",
        "\n",
        "HEADER_WRITTEN = False\n",
        "\n",
        "for file in tqdm(os.listdir(f'{pose_estimate_path}/adf')):\n",
        "    if 'pkl' in file:\n",
        "\n",
        "        adf = pd.read_pickle(os.path.join(f'{pose_estimate_path}/adf', file))\n",
        "\n",
        "        # angle features\n",
        "        feature_angle = adf.groupby(['bp','video']).apply(angle_features).reset_index(drop=True)\n",
        "        feature_angle = pd.pivot_table(feature_angle, index='video', columns=['bp'])\n",
        "        l0 = feature_angle.columns.get_level_values(1)\n",
        "        l1 = feature_angle.columns.get_level_values(0)\n",
        "        cols = [l1[i]+'_'+l0[i] for i in range(len(l1))]\n",
        "        feature_angle.columns = cols\n",
        "        feature_angle =feature_angle.reset_index()\n",
        "\n",
        "        # - measure of symmetry (left-right cross correlation)\n",
        "        corr_joint = adf.groupby(['video', 'part']).apply(lambda x:corr_lr(x,'angle')).reset_index()\n",
        "        corr_joint['part'] = 'lrCorr_angle_'+corr_joint['part']\n",
        "        corr_joint.columns = ['video', 'feature', 'Value']\n",
        "        corr_joint = pd.pivot_table(corr_joint, index='video', columns=['feature'])\n",
        "        l1 = corr_joint.columns.get_level_values(1)\n",
        "        corr_joint.columns = l1\n",
        "        corr_joint = corr_joint.reset_index()\n",
        "        feature_angle = pd.merge(feature_angle,corr_joint, on='video', how='outer')\n",
        "\n",
        "        if not HEADER_WRITTEN:\n",
        "            feature_angle.to_csv(f'{pose_estimate_path}/features_angle.csv', header=True, index=False)\n",
        "            HEADER_WRITTEN = True\n",
        "        else:\n",
        "            feature_angle.to_csv(f'{pose_estimate_path}/features_angle.csv', header=False, index=False, mode='a')"
      ],
      "metadata": {
        "id": "aPDofv7P3S1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute XY features\n",
        "\n",
        "HEADER_WRITTEN = False\n",
        "\n",
        "for file in tqdm(os.listdir(f'{pose_estimate_path}/xdf')):\n",
        "    if 'pkl' in file:\n",
        "\n",
        "        xdf = pd.read_pickle(os.path.join(f'{pose_estimate_path}/xdf', file))\n",
        "\n",
        "        # xy features\n",
        "        bps = ['LAnkle', 'RAnkle', 'LWrist', 'RWrist']\n",
        "        feature_xy = xdf[np.isin(xdf.bp, bps)].groupby(['bp','video']).apply(xy_features).reset_index(drop=True)\n",
        "        feature_xy = pd.pivot_table(feature_xy, index='video', columns=['bp'])\n",
        "        l0 = feature_xy.columns.get_level_values(1)\n",
        "        l1 = feature_xy.columns.get_level_values(0)\n",
        "        cols = [l1[i]+'_'+l0[i] for i in range(len(l1))]\n",
        "        feature_xy.columns = cols\n",
        "        feature_xy = feature_xy.reset_index()\n",
        "        # - measure of symmetry (left-right cross correlation)\n",
        "        xdf['dist'] = np.sqrt(xdf['x']**2+xdf['y']**2)\n",
        "        corr_joint = xdf.groupby(['video', 'part']).apply(lambda x:corr_lr(x,'dist')).reset_index()\n",
        "        corr_joint['part'] = 'lrCorr_x_'+corr_joint['part']\n",
        "        corr_joint.columns = ['video', 'feature', 'Value']\n",
        "        corr_joint = pd.pivot_table(corr_joint, index='video', columns=['feature'])\n",
        "        l1 = corr_joint.columns.get_level_values(1)\n",
        "        corr_joint.columns = l1\n",
        "        corr_joint = corr_joint.reset_index()\n",
        "        feature_xy = pd.merge(feature_xy, corr_joint, on='video', how='outer')\n",
        "\n",
        "        if not HEADER_WRITTEN:\n",
        "            feature_xy.to_csv(f'{pose_estimate_path}/features_xy.csv', header=True, index=False, mode='a')\n",
        "            HEADER_WRITTEN = True\n",
        "        else:\n",
        "            feature_xy.to_csv(f'{pose_estimate_path}/features_xy.csv', header=False, index=False, mode='a')"
      ],
      "metadata": {
        "id": "AenvmNmB3cc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine features\n",
        "\n",
        "SAVE = True\n",
        "\n",
        "if features_xy.empty or features_angle.empty:\n",
        "  features_xy = pd.read_csv(f'{pose_estimate_path}/features_xy.csv')\n",
        "  features_angle = pd.read_csv(f'{pose_estimate_path}/features_angle.csv')\n",
        "\n",
        "features = pd.merge(features_xy, features_angle, on='video', how='inner')"
      ],
      "metadata": {
        "id": "VhWbYFEQ5L8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split features based on video file naming convention\n",
        "\n",
        "features['infant'] = features['video'].str.split('_').str[0]\n",
        "features['session'] = features['video'].str.split('_').str[1]\n",
        "features['age'] = features['video'].str.split('_').str[6]\n",
        "\n",
        "if SAVE:\n",
        "    features.to_csv(f'{pose_estimate_path}/features.csv', header=True, index=False)"
      ],
      "metadata": {
        "id": "6fKR50_t6F3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Include data for the following, and restructure dataframe\n",
        "# Customize for your specific dataset\n",
        "\n",
        "id_vars = ['infant', 'age','corr_age', 'chrono_age', 'score','session','video']\n",
        "melted = pd.melt(features, id_vars=id_vars, var_name=\"feature\", value_name=\"Value\")\n"
      ],
      "metadata": {
        "id": "1cPm0nyI6WUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_str = melted.feature.str.split('_')\n",
        "\n",
        "side =pd.Series([ i[-1:][0][0] if i[0]!='lrCorr' else '' for i in feature_str])\n",
        "part =pd.Series([ i[-1:][0][1:] if i[0]!='lrCorr' else i[-1:][0] for i in feature_str])\n",
        "feature = pd.Series(['_'.join(i[:-1]) for i in feature_str])\n",
        "\n",
        "feature_attributes = pd.DataFrame.from_dict({'side': side, 'part': part, 'feature_name': feature})\n",
        "\n",
        "feature_attributes.feature_name.unique()\n",
        "melted[['side', 'part', 'feature']] = feature_attributes\n",
        "\n",
        "melted = melted.dropnans()\n",
        "mean = melted.groupby(['infant', 'age', 'corr_age', 'chrono_age', 'score', 'session', 'video', 'feature', 'part'])['Value'].mean().reset_index()\n",
        "mean.to_csv(f'{pose_estimate_path}/{dataset}_features_mean_by_side.csv', header=True, index=False)\n"
      ],
      "metadata": {
        "id": "Td9C5LWE67Iv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}