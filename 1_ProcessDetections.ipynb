{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngtR6tOyIFM-",
    "outputId": "12e32194-6ae4-45c0-f4e5-3e1a3d8c66f8"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys, os, cv2, glob, json, gc\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from moviepy.editor import VideoFileClip\n",
    "import skvideo.io\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import circstat as CS\n",
    "import scipy as sc\n",
    "import math, random\n",
    "\n",
    "import itertools\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from processing import *\n",
    "from kinematics import *\n",
    "from skeleton import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.makedirs('./data',exist_ok=True)\n",
    "os.makedirs('./utils',exist_ok=True)\n",
    "\n",
    "#download custom processing scripts if not already downloaded\n",
    "# !wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/kinematics.py\n",
    "# !wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/circstat.py\n",
    "# !wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/processing.py\n",
    "# !wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/skeleton.py\n",
    "\n",
    "#download example data or upload your own json annotations\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# Download example raw data from figshare or specify path to your own json annotations |\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "#!wget -P . https://figshare.com/ndownloader/articles/25316500/versions/1\n",
    "# #unzip data into ./data folder and remove zip file\n",
    "# !unzip ./1 -d ./data\n",
    "# !rm ./1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pjaLpviIFNA",
    "outputId": "25749e58-269a-48d4-aa72-667fc737ce05"
   },
   "outputs": [],
   "source": [
    "#uncomment install if running on google colab\n",
    "#%pip install scikit-video\n",
    "DEIDENTIFY = True #set to True to deidentify data, and exclude xy coordinates and pixel values from output\n",
    "OVERWRITE = True\n",
    "USE_CENTER_INSTANCE = False\n",
    "USE_BEST_INSTANCE = True\n",
    "\n",
    "dataset = 'CHOP'\n",
    "json_path = f'./data/Infant Pose Data/{dataset}/annotations'\n",
    "json_files = os.listdir(json_path)\n",
    "directory = f'./data'\n",
    "\n",
    "save_path = f'./pose_estimates/{dataset}_pose_estimates'\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "kp_mapping = {0:'Nose', 1:'Neck', 2:'RShoulder', 3:'RElbow', 4:'RWrist', 5:'LShoulder', 6:'LElbow',\n",
    "              7:'LWrist', 8:'RHip', 9:'RKnee', 10:'RAnkle', 11:'LHip',\n",
    "              12:'LKnee', 13:'LAnkle', 14:'REye', 15:'LEye', 16:'REar', 17:'LEar'}\n",
    "\n",
    "# Define the DataFrame columns as specified\n",
    "columns = ['video_number', 'video', 'bp', 'frame', 'x', 'y', 'c','fps', 'pixel_x', 'pixel_y', 'time', 'part_idx']\n",
    "data = []  # This will hold the data to be loaded into the DataFrame\n",
    "\n",
    "vid_info = pd.read_csv(f'./data/{dataset}_video_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQ7Dz7hYfoAg",
    "outputId": "dd4ea572-f5c7-4660-b7d2-f07381427692"
   },
   "outputs": [],
   "source": [
    "# format files as pkl with openpose standard and bodypart labels\n",
    "\n",
    "def process_file(args):\n",
    "    \"\"\"Function to process a single file.\"\"\"\n",
    "    file_number, file, json_path, save_path, vid_info, kp_mapping = args\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(json_path, file)\n",
    "    fname = file.split('.')[0]\n",
    "    interim = []\n",
    "\n",
    "    if not OVERWRITE and os.path.exists(f'{save_path}/{fname}.pkl'):\n",
    "        return\n",
    "\n",
    "    # Open and load the JSON data\n",
    "    try: \n",
    "        with open(file_path, 'r') as f:\n",
    "            frames = json.load(f)\n",
    "            info = vid_info[vid_info['video'] == fname]\n",
    "            fps = vid_info['fps'].values[0]\n",
    "\n",
    "            pixel_x = vid_info['width'].values[0]\n",
    "            pixel_y = vid_info['height'].values[0]\n",
    "            \n",
    "            center_x = pixel_x / 2\n",
    "            center_y = pixel_y / 2\n",
    "            \n",
    "            # Iterate through each frame in the JSON file\n",
    "            for frame in frames:\n",
    "                frame_id = frame['frame_id']\n",
    "                if 'instances' in frame and len(frame['instances']) > 0:\n",
    "\n",
    "                    if USE_CENTER_INSTANCE:\n",
    "                        instance_id = get_center_instance(frame['instances'], center_x, center_y)\n",
    "                    elif USE_BEST_INSTANCE:\n",
    "                        instance_id = get_best_instance(frame['instances'])\n",
    "                    else:\n",
    "                        instance_id = 0\n",
    "\n",
    "                    keypoints = frame['instances'][instance_id]['keypoints']\n",
    "                    confidence = frame['instances'][instance_id]['keypoint_scores']\n",
    "                    keypoints, confidence = convert_coco_to_openpose(keypoints, confidence)\n",
    "\n",
    "                    # Iterate through each keypoint\n",
    "                    for part_idx, (x, y) in enumerate(keypoints):\n",
    "\n",
    "                        bp = kp_mapping[part_idx]\n",
    "                        fps = fps\n",
    "                        time = frame_id / fps\n",
    "                        c = confidence[part_idx]\n",
    "\n",
    "                        row = [file_number, fname, bp, frame_id, x, y, c, fps, pixel_x, pixel_y, time, part_idx]\n",
    "                        interim.append(row)\n",
    "\n",
    "        interim_df = pd.DataFrame(interim, columns=columns)\n",
    "        interim_df.to_csv(f'{save_path}/{fname}.csv', index=False)\n",
    "\n",
    "        del interim_df\n",
    "        return\n",
    "    \n",
    "    except Exception as e:\n",
    "        return\n",
    "    \n",
    "def process_annotations_multiprocess(json_files, json_path, save_path, vid_info, kp_mapping):\n",
    "    \"\"\"Run the annotation processing using multiprocessing.\"\"\"\n",
    "    args = [\n",
    "        (file_number, file, json_path, save_path, vid_info, kp_mapping)\n",
    "        for file_number, file in enumerate(json_files)\n",
    "    ]\n",
    "\n",
    "    # Set up a pool of workers\n",
    "    with Pool(processes=20) as pool:\n",
    "        pool.map(process_file, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_annotations_multiprocess(json_files, json_path, save_path, vid_info, kp_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gF9SA7KO1jbQ",
    "outputId": "0f87b278-d65f-4fba-9149-bd36844f6390"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2979/2979 [09:04<00:00,  5.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ensure the save_path directory exists\n",
    "save_path = f'./pose_estimates/{dataset}_norm'\n",
    "\n",
    "if os.path.exists(f'{save_path}/pose_estimates_{dataset}.csv'):\n",
    "    os.remove(f'{save_path}/pose_estimates_{dataset}.csv')\n",
    "    print('Removed existing CSV file')\n",
    "\n",
    "for pklfile in tqdm(os.listdir(save_path)):\n",
    "    if not pklfile.endswith('.pkl'):\n",
    "        continue\n",
    "    else:\n",
    "        interim_df = pd.read_pickle(f'{save_path}/{pklfile}')\n",
    "        interim_df.to_csv(f'{save_path}/pose_estimates_{dataset}.csv', mode='a', header=False, index=False)\n",
    "\n",
    "    del interim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ERK1DQ-92DsG"
   },
   "outputs": [],
   "source": [
    "csv_path = f'{save_path}/pose_estimates_{dataset}.csv'\n",
    "output_csv_path = f'{save_path}/pose_estimates_{dataset}_b.csv'\n",
    "chunksize = 1000  # Number of rows per chunk\n",
    "\n",
    "# Define the new headers\n",
    "new_headers = ['video_number', 'video', 'bp', 'frame', 'x', 'y', 'c', 'fps', 'pixel_x', 'pixel_y', 'time', 'part_idx']\n",
    "\n",
    "# Read the CSV file in chunks\n",
    "chunk_iterator = pd.read_csv(csv_path, chunksize=chunksize)\n",
    "\n",
    "# Process the first chunk\n",
    "first_chunk = next(chunk_iterator)\n",
    "first_chunk.columns = new_headers\n",
    "first_chunk.to_csv(output_csv_path, mode='w', index=False)\n",
    "\n",
    "# Process the rest of the chunks and append them to the new CSV file without headers\n",
    "for chunk in chunk_iterator:\n",
    "    chunk.columns = new_headers\n",
    "    chunk.to_csv(output_csv_path, mode='a', index=False, header=False)\n",
    "\n",
    "# rename the csv file\n",
    "os.rename(csv_path, f'{save_path}/pose_estimates_{dataset}_x.csv')\n",
    "os.rename(output_csv_path, csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "I4107PvX25fK"
   },
   "outputs": [],
   "source": [
    "# Smooth detections and compute features\n",
    "pose_estimate_path = f'./pose_estimates/{dataset}_pose_estimates'\n",
    "csv_path = f'{pose_estimate_path}/pose_estimates_{dataset}.csv'\n",
    "save_path = f'{pose_estimate_path}/pose_estimates_{dataset}_processed.csv'\n",
    "\n",
    "# List of subdirectories to create\n",
    "subdirs = [\n",
    "    \"\",\n",
    "    \"xdf\",\n",
    "    \"adf\",\n",
    "    \"xy_features\",\n",
    "    \"angle_features\",\n",
    "    \"xy_features/total\",\n",
    "    \"angle_features/total\",\n",
    "    \"xy_features/windows\",\n",
    "    \"angle_features/windows\",\n",
    "    \"smooth\",\n",
    "    \"anim\"\n",
    "]\n",
    "\n",
    "# Create necessary directories\n",
    "for subdir in subdirs:\n",
    "    os.makedirs(f'{pose_estimate_path}/{subdir}', exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "H5A-LkovEMav"
   },
   "outputs": [],
   "source": [
    "def process_dataframe(file):\n",
    "    df = pd.read_csv(os.path.join(pose_estimate_path, file))\n",
    "\n",
    "    if df.empty:\n",
    "        #print(\"DataFrame is empty, skipping processing.\")\n",
    "        return\n",
    "    # print(f\"Processing DataFrame for video_number: {df['video_number'].iloc[0]}\")\n",
    "    try:\n",
    "        if dataset == 'Youtube':\n",
    "            session = df['video'].unique()[0].split('_')[1][0]\n",
    "            infant = df['video'].unique()[0].split('_')[1][3:]\n",
    "            age = '3Month'\n",
    "        elif dataset == 'Clinical':\n",
    "            # split based on naming convention\n",
    "            session = df['video'].unique()[0].split('_')[1][1]\n",
    "            infant = df['video'].unique()[0].split('_')[0][-1]\n",
    "            age = '3Month'\n",
    "        elif dataset == 'gma_score_prediction': \n",
    "            session = 0\n",
    "            infant = df['video'].unique()[0]\n",
    "            age = '3Month'\n",
    "        elif dataset == 'CHOP': \n",
    "            session = df['video'].unique()[0].split('_')[1]\n",
    "            infant = df['video'].unique()[0].split('_')[0]\n",
    "            age = df['video'].unique()[0].split('_')[2]\n",
    "        \n",
    "        # print(f'infant: {infant} {session} {age}')\n",
    "\n",
    "\n",
    "        median_window = 1\n",
    "        mean_window = 1\n",
    "        delta_window = 0.25  # Smoothing applied to delta_x, velocity, acceleration\n",
    "\n",
    "        df['x'] = pd.to_numeric(df['x'])\n",
    "        df['y'] = pd.to_numeric(df['y'])\n",
    "\n",
    "        # Interpolate\n",
    "        df = df.groupby(['video', 'bp']).apply(interpolate_df).reset_index(drop=True)\n",
    "\n",
    "        # Median and mean filter\n",
    "        median_window = 0.5\n",
    "        mean_window = 0.5\n",
    "        df = df.groupby(['video', 'bp']).apply(lambda x: smooth(x, 'y', median_window, mean_window)).reset_index(drop=True)\n",
    "        df = df.groupby(['video', 'bp']).apply(lambda x: smooth(x, 'x', median_window, mean_window)).reset_index(drop=True)\n",
    "        \n",
    "        df = normalise_skeletons(df)\n",
    "        df.to_csv(f'{pose_estimate_path}/smooth/{infant}_{session}_{age}_smooth_norm.csv')\n",
    "    \n",
    "    except:\n",
    "        f'could not process video {df[\"video\"].unique()[0]}'\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Rotate and normalise by reference\n",
    "        xdf = get_dynamics_xy(df, delta_window)    \n",
    "        xdf.to_csv(f'{pose_estimate_path}/xdf/{infant}_{session}_{age}_smooth_norm_xy.pkl')\n",
    "\n",
    "        adf = get_joint_angles(df)\n",
    "        adf = get_dynamics_angle(adf, delta_window)\n",
    "        adf.to_csv(f'{pose_estimate_path}/adf/{infant}_{session}_{age}_smooth_norm_ang.pkl')\n",
    "\n",
    "    except KeyError as e:\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2979 files\n"
     ]
    }
   ],
   "source": [
    "pose_estimate_files = os.listdir(pose_estimate_path)\n",
    "pose_estimate_files = [file for file in pose_estimate_files if file.endswith('.csv')]\n",
    "\n",
    "# pose_estimate_files = random.sample(pose_estimate_files, 10)\n",
    "\n",
    "print(f'Processing {len(pose_estimate_files)} files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=25) as pool:\n",
    "    pool.map(process_dataframe, pose_estimate_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0],\n",
    "          [0, 255, 0], \\\n",
    "          [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255],\n",
    "          [85, 0, 255], \\\n",
    "          [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85],[255, 0, 0]]\n",
    "\n",
    "limbSeq = [[2, 3], [2, 6], [3, 4], [4, 5], [6, 7], [7, 8], [2, 9], [9, 10], \\\n",
    "           [10, 11], [2, 12], [12, 13], [13, 14], [2, 1], [1, 15], [15, 17], \\\n",
    "           [1, 16], [16, 18]] #[3, 17], [6, 18]]\n",
    "\n",
    "def plot_skel(df, ax, xvar, yvar):\n",
    "    alpha = 0.3\n",
    "\n",
    "    for i, limb in enumerate(limbSeq):\n",
    "        l1 = limb[0] - 1\n",
    "        l2 = limb[1] - 1\n",
    "        df_l1 = df[df.part_idx == l1]\n",
    "        df_l2 = df[df.part_idx == l2]\n",
    "        if not df_l1.empty and not df_l2.empty:\n",
    "            ax.plot(\n",
    "                [df_l1[xvar].iloc[0], df_l2[xvar].iloc[0]],\n",
    "                [df_l1[yvar].iloc[0], df_l2[yvar].iloc[0]],\n",
    "                linewidth=5,\n",
    "                color=[j / 255 for j in colors[i]],\n",
    "                alpha=alpha,\n",
    "            )\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        ax.plot(\n",
    "            df.iloc[i][xvar],\n",
    "            df.iloc[i][yvar],\n",
    "            'o',\n",
    "            markersize=10,\n",
    "            color=[j / 255 for j in colors[i]],\n",
    "            alpha=alpha,\n",
    "        )\n",
    "\n",
    "\n",
    "def animate_coordinates_with_skeleton(file):\n",
    "    \n",
    "    file = f'{pose_estimate_path}/smooth/{file}'\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    fname = os.path.basename(file)\n",
    "\n",
    "    fps = df.fps[0]\n",
    "    framen = df.frame.max()\n",
    "    frame_interval = 5\n",
    "    dpi = 80\n",
    "\n",
    "    output_gif = f'{pose_estimate_path}/anim/{os.path.splitext(fname)[0]}.gif'\n",
    "    print(output_gif)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6), dpi=dpi)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_ylim(-3, 3)\n",
    "    ax.invert_yaxis()\n",
    "    ax.axis('off')\n",
    "\n",
    "    def update(frame_idx):\n",
    "        ax.clear()\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.set_xlim(-3, 3)\n",
    "        ax.set_ylim(-3, 3)\n",
    "        ax.invert_yaxis()\n",
    "        ax.axis('off')\n",
    "        plot_skel(df[df.frame == frame_idx], ax, 'x', 'y')\n",
    "\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig,\n",
    "        update,\n",
    "        frames=range(0, framen, frame_interval),\n",
    "        interval=int(1 / fps * 1000 * frame_interval),\n",
    "        repeat_delay=1000\n",
    "    )\n",
    "\n",
    "    ani.save(output_gif, dpi=dpi)\n",
    "    plt.close(fig)\n",
    "\n",
    "    del ani, df, fig, ax\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1289_3_1_smooth_norm.csv', '63278_1_0_smooth_norm.csv', '93989_1_0_smooth_norm.csv', '76803_1_0_smooth_norm.csv', '74_1_0_smooth_norm.csv']\n"
     ]
    }
   ],
   "source": [
    "smooth_files = os.listdir(f'{pose_estimate_path}/smooth')\n",
    "smooth_files = [file for file in smooth_files if file.endswith('.csv')]\n",
    "\n",
    "smooth_files = random.sample(smooth_files, 5)\n",
    "\n",
    "print(smooth_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./pose_estimates/CHOP_pose_estimates/anim/63278_1_0_smooth_norm.gif\n",
      "./pose_estimates/CHOP_pose_estimates/anim/74_1_0_smooth_norm.gif\n",
      "./pose_estimates/CHOP_pose_estimates/anim/1289_3_1_smooth_norm.gif./pose_estimates/CHOP_pose_estimates/anim/76803_1_0_smooth_norm.gif\n",
      "\n",
      "./pose_estimates/CHOP_pose_estimates/anim/93989_1_0_smooth_norm.gif\n"
     ]
    }
   ],
   "source": [
    "with Pool(processes=5) as pool:\n",
    "    pool.map(animate_coordinates_with_skeleton, smooth_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<matplotlib.lines.Line2D object at 0x7f02603badf0>, <matplotlib.lines.Line2D object at 0x7f02603c7130>, <matplotlib.lines.Line2D object at 0x7f02603c73d0>, <matplotlib.lines.Line2D object at 0x7f02603c7670>, <matplotlib.lines.Line2D object at 0x7f02603c77f0>, <matplotlib.lines.Line2D object at 0x7f02603c7a90>, <matplotlib.lines.Line2D object at 0x7f02603c7d30>, <matplotlib.lines.Line2D object at 0x7f02603c7fd0>, <matplotlib.lines.Line2D object at 0x7f02603d62b0>, <matplotlib.lines.Line2D object at 0x7f02603d6550>, <matplotlib.lines.Line2D object at 0x7f02603bae50>, <matplotlib.lines.Line2D object at 0x7f02603d6a60>, <matplotlib.lines.Line2D object at 0x7f02603d6d00>, <matplotlib.lines.Line2D object at 0x7f02603d6fa0>, <matplotlib.lines.Line2D object at 0x7f0260360280>, <matplotlib.lines.Line2D object at 0x7f0260360520>, <matplotlib.lines.Line2D object at 0x7f02603607c0>, <matplotlib.lines.Line2D object at 0x7f0260360a60>, <matplotlib.lines.Line2D object at 0x7f0260360d00>, <matplotlib.collections.PathCollection object at 0x7f0260360f40>, Text(0, 1, '')]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file = smooth_files[0]\n",
    "file_path = f'{pose_estimate_path}/smooth/{file}'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "try:\n",
    "    df.rename(columns={'file_number': 'video_number', 'fname': 'video', 'frame_id': 'frame'}, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "# Ensure required columns exist\n",
    "required_columns = ['frame', 'x', 'y', 'part_idx']\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    raise ValueError(\"Input CSV is missing required columns: 'frame', 'x', 'y', 'part_idx'\")\n",
    "\n",
    "# Sort the data by frame\n",
    "df = df.sort_values(by='frame')\n",
    "\n",
    "# Extract unique frame IDs\n",
    "frame_ids = df['frame'].unique()\n",
    "\n",
    "# Initialize the figure\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.set_xlim(-3, 3)  # Adjust based on your data range\n",
    "ax.set_ylim(-1.2, 1.2)  # Adjust based on your data range\n",
    "ax.set_title(\"Time Series of Keypoints with Skeleton\")\n",
    "ax.set_xlabel(\"Normalized X\")\n",
    "ax.set_ylabel(\"Normalized Y\")\n",
    "\n",
    "limb_lines = [ax.plot([], [], linewidth=5, alpha=0.7)[0] for _ in limbSeq]  # List of line objects\n",
    "keypoints = ax.scatter([], [], s=50, alpha=0.7)  # Scatter plot for keypoints\n",
    "text = ax.text(0, 1, '', fontsize=12)\n",
    "\n",
    "x = limb_lines + [keypoints, text]  # Flattened list of all artists\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting animation process...\n",
      "Starting animation process...\n",
      "Starting animation process...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'set_animated'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/tmp/ipykernel_3598078/1088966507.py\", line 116, in animate_skel\n    animate_coordinates_with_skeleton(input_file, output_gif=output_gif)\n  File \"/tmp/ipykernel_3598078/1088966507.py\", line 96, in animate_coordinates_with_skeleton\n    ani = FuncAnimation(\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/animation.py\", line 1694, in __init__\n    super().__init__(fig, **kwargs)\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/animation.py\", line 1416, in __init__\n    super().__init__(fig, event_source=event_source, *args, **kwargs)\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/animation.py\", line 880, in __init__\n    self._setup_blit()\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/animation.py\", line 1209, in _setup_blit\n    self._post_draw(None, self._blit)\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/animation.py\", line 1164, in _post_draw\n    self._fig.canvas.draw_idle()\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/backend_bases.py\", line 2082, in draw_idle\n    self.draw(*args, **kwargs)\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\", line 400, in draw\n    self.figure.draw(self.renderer)\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/artist.py\", line 95, in draw_wrapper\n    result = draw(artist, renderer, *args, **kwargs)\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/artist.py\", line 72, in draw_wrapper\n    return draw(artist, renderer)\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/figure.py\", line 3185, in draw\n    DrawEvent(\"draw_event\", self.canvas, renderer)._process()\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/backend_bases.py\", line 1263, in _process\n    self.canvas.callbacks.process(self.name, self)\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\", line 319, in process\n    self.exception_handler(exc)\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\", line 103, in _exception_printer\n    raise exc\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\", line 314, in process\n    func(*args, **kwargs)\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/animation.py\", line 904, in _start\n    self._init_draw()\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/site-packages/matplotlib/animation.py\", line 1756, in _init_draw\n    a.set_animated(self._blit)\nAttributeError: 'list' object has no attribute 'set_animated'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m smooth_files \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(smooth_files, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43manimate_skel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmooth_files\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda/envs/predict_gma/lib/python3.8/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda/envs/predict_gma/lib/python3.8/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'set_animated'"
     ]
    }
   ],
   "source": [
    "smooth_files = os.listdir(f'{pose_estimate_path}/smooth')\n",
    "smooth_files = random.sample(smooth_files, 3)\n",
    "\n",
    "with Pool(processes=5) as pool:\n",
    "    pool.map(animate_skel, smooth_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u0ik4gOyCDVZ",
    "outputId": "f16fdcc3-5798-47cc-f78c-282d79d7e7ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing remaining rows in the buffer...\n",
      "Processing DataFrame for video_number: 2978\n",
      "infant: 151 1 0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "chunksize = 100000\n",
    "buffer = pd.DataFrame()\n",
    "\n",
    "# Read the CSV file in chunks\n",
    "chunk_iterator = pd.read_csv(csv_path, chunksize=chunksize)\n",
    "\n",
    "for chunk in chunk_iterator:\n",
    "  unique_videos = chunk['video_number'].unique()\n",
    "\n",
    "  for video_number in unique_videos:\n",
    "      video_chunk = chunk[chunk['video_number'] == video_number]\n",
    "\n",
    "      if not buffer.empty:\n",
    "        if buffer['video_number'].iloc[0] == video_number:\n",
    "\n",
    "            buffer = pd.concat([buffer, video_chunk], ignore_index=True)\n",
    "            if video_number not in chunk['video_number'].values:\n",
    "                process_dataframe(buffer, pose_estimate_path)\n",
    "                buffer = pd.DataFrame()\n",
    "\n",
    "        else:\n",
    "            process_dataframe(buffer, pose_estimate_path)\n",
    "            buffer = video_chunk\n",
    "      else:\n",
    "          buffer = video_chunk\n",
    "  clear_output(wait=True)\n",
    "  chunk = chunk[~chunk['video_number'].isin(unique_videos)]\n",
    "\n",
    "# # Process any remaining rows in the buffer\n",
    "if not buffer.empty:\n",
    "    print(\"Processing remaining rows in the buffer...\")\n",
    "    process_dataframe(buffer, pose_estimate_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AenvmNmB3cc5",
    "outputId": "7925b160-4c5f-45f2-fe96-c02775cf3106"
   },
   "outputs": [],
   "source": [
    "#compute xy features\n",
    "\n",
    "def process_xdf_file(file): \n",
    "        if 'pkl' in file:\n",
    "             xdf = pd.read_pickle(os.path.join(f'{pose_estimate_path}/xdf', file))\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "        bps = ['LAnkle', 'RAnkle', 'LWrist', 'RWrist']\n",
    "        filtered_xdf = xdf[np.isin(xdf.bp, bps)]\n",
    "        video_number = xdf.video.unique()[0]\n",
    "        \n",
    "        # Compute window xy features: \n",
    "        mean_type = 'windows'\n",
    "        feature_xy = xdf.groupby(['bp', 'video']).apply(lambda group: rolling_xy_features(group, window_size=60)).reset_index(drop=True)\n",
    "        feature_xy = pd.pivot_table(feature_xy, index=['video','frame'], columns=['bp'])\n",
    "           \n",
    "        l0 = feature_xy.columns.get_level_values(1)\n",
    "        l1 = feature_xy.columns.get_level_values(0)\n",
    "\n",
    "        cols = [l1[i]+'_'+l0[i] for i in range(len(l1))]\n",
    "        feature_xy.columns = cols\n",
    "        feature_xy = feature_xy.reset_index()\n",
    "\n",
    "        # - measure of symmetry (left-right cross correlation)\n",
    "        xdf['dist'] = np.sqrt(xdf['x']**2+xdf['y']**2)\n",
    "        corr_joint = xdf[np.isin(xdf.bp, bps)].groupby(['video', 'part']).apply(lambda x:rolling_corr_lr(x,var='dist')).reset_index()\n",
    "        corr_joint['part'] = 'lrCorr_x_'+corr_joint['part']\n",
    "        corr_joint.drop(columns=['level_2','R','L'],inplace=True)\n",
    "\n",
    "        corr_joint.columns = ['video', 'feature', 'frame', 'Value']\n",
    "        corr_joint = pd.pivot_table(corr_joint, index=['video', 'frame'], columns=['feature'])\n",
    "        l1 = corr_joint.columns.get_level_values(1)\n",
    "        corr_joint.columns = l1\n",
    "        corr_joint = corr_joint.reset_index()\n",
    "        feature_xy = pd.merge(feature_xy, corr_joint, on=['video','frame'], how='outer')\n",
    "\n",
    "        feature_xy.to_csv(f'{pose_estimate_path}/xy_features/{mean_type}/{video_number}_features_{mean_type}_xy.csv', header=True, index=False)\n",
    "    \n",
    "        #compute total xy features (average by video)\n",
    "        mean_type = 'total'\n",
    "\n",
    "        feature_xy = filtered_xdf.groupby(['bp','video']).apply(xy_features).reset_index(drop=True)\n",
    "        feature_xy = pd.pivot_table(feature_xy, index='video', columns=['bp'])\n",
    "        l0 = feature_xy.columns.get_level_values(1)\n",
    "        l1 = feature_xy.columns.get_level_values(0)\n",
    "        cols = [l1[i]+'_'+l0[i] for i in range(len(l1))]\n",
    "        feature_xy.columns = cols\n",
    "        feature_xy = feature_xy.reset_index()\n",
    "\n",
    "        # - measure of symmetry (left-right cross correlation)\n",
    "\n",
    "        xdf['dist'] = np.sqrt(xdf['x']**2+xdf['y']**2)\n",
    "        corr_joint = xdf.groupby(['video', 'part']).apply(lambda x:corr_lr(x,'dist')).reset_index()\n",
    "        corr_joint['part'] = 'lrCorr_x_'+corr_joint['part']\n",
    "        corr_joint.columns = ['video', 'feature', 'Value']\n",
    "        corr_joint = pd.pivot_table(corr_joint, index='video', columns=['feature'])\n",
    "        l1 = corr_joint.columns.get_level_values(1)\n",
    "        corr_joint.columns = l1\n",
    "        corr_joint = corr_joint.reset_index()\n",
    "        feature_xy = pd.merge(feature_xy, corr_joint, on='video', how='outer')\n",
    "        \n",
    "        feature_xy.to_csv(f'{pose_estimate_path}/xy_features/{mean_type}/{video_number}_features_{mean_type}_xy.csv', header=True, index=False)\n",
    "\n",
    "        return\n",
    "\n",
    "# Compute angular features\n",
    "\n",
    "def process_adf_file(file): \n",
    "        if 'pkl' in file:\n",
    "             adf = pd.read_pickle(os.path.join(f'{pose_estimate_path}/adf', file))\n",
    "        else:\n",
    "            return       \n",
    "\n",
    "        video_number = adf.video.unique()[0]\n",
    "\n",
    "        # Compute window angle features: \n",
    "        mean_type = 'windows'\n",
    "        window_size = 2*int(adf['fps'].iloc[0]) # 2 seconds\n",
    "\n",
    "        # Compute window angle features: \n",
    "        feature_angle = adf.groupby(['bp','video']).apply(rolling_angle_features, window_size=window_size).reset_index(drop=True)\n",
    "        feature_angle = pd.pivot_table(feature_angle, index=['video','frame'], columns=['bp'])\n",
    "        l0 = feature_angle.columns.get_level_values(1)\n",
    "        l1 = feature_angle.columns.get_level_values(0)\n",
    "        cols = [l1[i]+'_'+l0[i] for i in range(len(l1))]\n",
    "        feature_angle.columns = cols\n",
    "        feature_angle =feature_angle.reset_index()\n",
    "\n",
    "        # - measure of symmetry (left-right cross correlation)\n",
    "        corr_joint = adf.groupby(['video', 'part']).apply(rolling_core_lr, window_size=window_size, min_periods=1, var='angle')\n",
    "        corr_joint.reset_index(inplace=True)\n",
    "        corr_joint.drop(columns=['level_2','R','L'],inplace=True)\n",
    "        corr_joint['part'] = 'lrCorr_angle_'+corr_joint['part']\n",
    "        corr_joint.columns = ['video', 'feature', 'frame','Value']\n",
    "        corr_joint = pd.pivot_table(corr_joint, index=['video','frame'], columns=['feature'])\n",
    "        l1 = corr_joint.columns.get_level_values(1)\n",
    "        corr_joint.columns = l1\n",
    "        corr_joint = corr_joint.reset_index()\n",
    "\n",
    "        feature_angle = pd.merge(feature_angle,corr_joint, on=['video','frame'], how='outer')\n",
    "        feature_angle.to_csv(f'{pose_estimate_path}/angle_features/{mean_type}/{video_number}_features_{mean_type}_angle.csv', header=True, index=False)\n",
    "\n",
    "        #compute total angle features (average by video)\n",
    "        mean_type = 'total'\n",
    "        feature_angle = adf.groupby(['bp','video']).apply(angle_features).reset_index(drop=True)\n",
    "        feature_angle = pd.pivot_table(feature_angle, index='video', columns=['bp'])        \n",
    "        \n",
    "        l0 = feature_angle.columns.get_level_values(1)\n",
    "        l1 = feature_angle.columns.get_level_values(0)\n",
    "        cols = [l1[i]+'_'+l0[i] for i in range(len(l1))]\n",
    "        feature_angle.columns = cols\n",
    "        feature_angle =feature_angle.reset_index()\n",
    "\n",
    "        # - measure of symmetry (left-right cross correlation)\n",
    "        corr_joint = adf.groupby(['video', 'part']).apply(lambda x:corr_lr(x,'angle')).reset_index()\n",
    "        corr_joint['part'] = 'lrCorr_angle_'+corr_joint['part']\n",
    "        corr_joint.columns = ['video', 'feature', 'Value']\n",
    "        corr_joint = pd.pivot_table(corr_joint, index='video', columns=['feature'])\n",
    "        l1 = corr_joint.columns.get_level_values(1)\n",
    "        corr_joint.columns = l1\n",
    "        corr_joint = corr_joint.reset_index()\n",
    "        feature_angle = pd.merge(feature_angle,corr_joint, on='video', how='outer')\n",
    "\n",
    "        feature_angle.to_csv(f'{pose_estimate_path}/angle_features/{mean_type}/{video_number}_features_{mean_type}_angle.csv', header=True, index=False)\n",
    "        \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=20)  # Adjust the number of processes as needed\n",
    "file_paths = os.listdir(f'{pose_estimate_path}/xdf')  # List of file paths\n",
    "results = pool.map(process_xdf_file, file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rolling_core_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/miniconda/envs/predict_gma/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/tmp/ipykernel_2478/2113079971.py\", line 91, in process_adf_file\n    corr_joint = adf.groupby(['video', 'part']).apply(rolling_core_lr, window_size=window_size, min_periods=1, var='angle')\nNameError: name 'rolling_core_lr' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m pool \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)  \u001b[38;5;66;03m# Adjust the number of processes as needed\u001b[39;00m\n\u001b[1;32m      2\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpose_estimate_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/adf\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# List of file paths\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_adf_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda/envs/predict_gma/lib/python3.8/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda/envs/predict_gma/lib/python3.8/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rolling_core_lr' is not defined"
     ]
    }
   ],
   "source": [
    "pool = multiprocessing.Pool(processes=20)  # Adjust the number of processes as needed\n",
    "file_paths = os.listdir(f'{pose_estimate_path}/adf')  # List of file paths\n",
    "results = pool.map(process_adf_file, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhWbYFEQ5L8X"
   },
   "outputs": [],
   "source": [
    "# Combine global features \n",
    "SAVE = True\n",
    "\n",
    "features_xy = pd.DataFrame()\n",
    "features_angle = pd.DataFrame()\n",
    "\n",
    "for csv in os.listdir(f'{pose_estimate_path}/xy_features/total'):\n",
    "    df = pd.read_csv(f'{pose_estimate_path}/xy_features/total/{csv}')\n",
    "    features_xy = pd.concat([features_xy, df], axis=0)\n",
    "\n",
    "for csv in os.listdir(f'{pose_estimate_path}/angle_features/total'):\n",
    "    df = pd.read_csv(f'{pose_estimate_path}/angle_features/total/{csv}')\n",
    "    features_angle = pd.concat([features_angle, df], axis=0)\n",
    "\n",
    "features = pd.merge(features_xy, features_angle, on='video', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{pose_estimate_path}/window_features', exist_ok=True)\n",
    "\n",
    "for csv in os.listdir(f'{pose_estimate_path}/xy_features/windows'):\n",
    "    video_number = csv.split('_')[0]\n",
    "    xy = pd.read_csv(f'{pose_estimate_path}/xy_features/windows/{csv}')   \n",
    "    ang = pd.read_csv(f'{pose_estimate_path}/xy_features/windows/{csv}'.replace('xy','angle'))\n",
    "\n",
    "    features = pd.merge(xy, ang, on=['video','frame'], how='inner').dropna()\n",
    "    features.to_csv(f'{pose_estimate_path}/window_features/{csv}'.replace('xy','all'), header=True, index=False)\n",
    "\n",
    "    del xy, ang, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fKR50_t6F3n"
   },
   "outputs": [],
   "source": [
    "# Split features based on video file naming convention\n",
    "\n",
    "if dataset == 'Youtube':\n",
    "    features['infant'] = features['video'].str.split('_').str.get(1).str[-3:]\n",
    "    features['session'] = features['video'].str.split('_').str.get(1).str[0]\n",
    "    features['age'] = 'month'\n",
    "\n",
    "elif dataset == 'Clinical':\n",
    "    features['infant'] = features['video'].str.split('_').str.get(0).str[-1]\n",
    "    features['session'] = features['video'].str.split('_').str.get(1).str[1]\n",
    "    features['age'] = 'month'\n",
    "\n",
    "elif dataset == 'gma_score_prediction':\n",
    "    features['infant'] = features['video']\n",
    "    features['session'] = 0\n",
    "    features['age'] = '3_4_Month'\n",
    "\n",
    "if SAVE:\n",
    "    features.to_csv(f'{pose_estimate_path}/features.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "Fw5_xTrfi9tA"
   },
   "outputs": [],
   "source": [
    "# Body parts and sides\n",
    "body_parts = [\"Knee\", \"Shoulder\", \"Hip\", \"Elbow\", \"Wrist\", \"Ankle\"]\n",
    "sides = [\"L\", \"R\"]\n",
    "\n",
    "# Function to split the feature string into \"feature\", \"part\", and \"side\"\n",
    "def split_feature(feature):\n",
    "    # Split the feature into components\n",
    "    parts = feature.split('_')\n",
    "    feature_name = \"_\".join(parts[:-1])  # Default to everything before the last part\n",
    "    part = parts[-1] if len(parts) > 1 else \"\"  # Default to the last part\n",
    "\n",
    "    side = \"\"\n",
    "\n",
    "    # Check if the last part has a side\n",
    "    for body_part in body_parts:\n",
    "        if body_part in part:  # Find body part\n",
    "            idx = part.index(body_part)\n",
    "            if idx > 0 and part[idx-1] in sides:  # Check for side prefix\n",
    "                side = part[idx-1]\n",
    "                part = part[idx:]  # Remove the side from the part\n",
    "            break  # Exit loop after finding the body part\n",
    "\n",
    "    # Adjust feature name to remove body part and side, if found\n",
    "    if part in feature_name:\n",
    "        feature_name = feature_name.replace(part, \"\").strip(\"_\")\n",
    "    if side in feature_name:\n",
    "        feature_name = feature_name.replace(side, \"\").strip(\"_\")\n",
    "\n",
    "    return pd.Series([feature_name, part, side])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Td9C5LWE67Iv",
    "outputId": "732f3a60-77ef-4ccb-a7f9-921c9edc7863"
   },
   "outputs": [],
   "source": [
    "# Include data for the following, and restructure dataframe\n",
    "# Customize for your specific dataset\n",
    "\n",
    "id_vars = ['infant', 'age','session','video']\n",
    "melted = pd.melt(features, id_vars=id_vars, var_name=\"feature\", value_name=\"Value\")\n",
    "\n",
    "# Apply the function to the 'feature' column in your melted DataFrame\n",
    "melted[['feature', 'part', 'side']] = melted['feature'].apply(split_feature)\n",
    "melted = melted.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infant</th>\n",
       "      <th>age</th>\n",
       "      <th>session</th>\n",
       "      <th>video</th>\n",
       "      <th>feature</th>\n",
       "      <th>Value</th>\n",
       "      <th>part</th>\n",
       "      <th>side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>month</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>IQRaccx</td>\n",
       "      <td>0.493071</td>\n",
       "      <td>Ankle</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>month</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>IQRaccx</td>\n",
       "      <td>0.137097</td>\n",
       "      <td>Ankle</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>month</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>IQRaccx</td>\n",
       "      <td>0.494380</td>\n",
       "      <td>Ankle</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>month</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IQRaccx</td>\n",
       "      <td>0.228970</td>\n",
       "      <td>Ankle</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>month</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>IQRaccx</td>\n",
       "      <td>0.201175</td>\n",
       "      <td>Ankle</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   infant    age  session  video  feature     Value   part side\n",
       "0      92  month        0     92  IQRaccx  0.493071  Ankle    L\n",
       "1      61  month        0     61  IQRaccx  0.137097  Ankle    L\n",
       "2      20  month        0     20  IQRaccx  0.494380  Ankle    L\n",
       "3       0  month        0      0  IQRaccx  0.228970  Ankle    L\n",
       "4      21  month        0     21  IQRaccx  0.201175  Ankle    L"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infant</th>\n",
       "      <th>age</th>\n",
       "      <th>session</th>\n",
       "      <th>video</th>\n",
       "      <th>feature</th>\n",
       "      <th>part</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>month</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IQR_acc_angle</td>\n",
       "      <td>Elbow</td>\n",
       "      <td>40.774830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>month</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IQR_acc_angle</td>\n",
       "      <td>Hip</td>\n",
       "      <td>17.346442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>month</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IQR_acc_angle</td>\n",
       "      <td>Knee</td>\n",
       "      <td>27.906233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>month</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IQR_acc_angle</td>\n",
       "      <td>Shoulder</td>\n",
       "      <td>29.657646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>month</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IQR_vel_angle</td>\n",
       "      <td>Elbow</td>\n",
       "      <td>8.443784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   infant    age  session  video        feature      part      Value\n",
       "0       0  month        0      0  IQR_acc_angle     Elbow  40.774830\n",
       "1       0  month        0      0  IQR_acc_angle       Hip  17.346442\n",
       "2       0  month        0      0  IQR_acc_angle      Knee  27.906233\n",
       "3       0  month        0      0  IQR_acc_angle  Shoulder  29.657646\n",
       "4       0  month        0      0  IQR_vel_angle     Elbow   8.443784"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = melted.groupby(['infant', 'age', 'session', 'video', 'feature', 'part'])['Value'].mean().reset_index()\n",
    "mean.to_csv(f'{pose_estimate_path}/{dataset}_features_mean_by_side.csv', header=True, index=False)\n",
    "\n",
    "mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLCqy4CzZtsZ"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "predict_gma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
