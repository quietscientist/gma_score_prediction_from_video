{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!sudo apt install python3.8-full python3-pip\n",
    "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import json\n",
    "import numpy as np\n",
    "import os, cv2, glob, json, gc\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from itertools import chain\n",
    "from moviepy.editor import VideoFileClip\n",
    "import skvideo.io\n",
    "from tqdm import tqdm\n",
    "import circstat as CS\n",
    "import scipy as sc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "np.float = np.float64\n",
    "np.int = np.int_\n",
    "\n",
    "# COCO limb sequence (0-based indexing)\n",
    "coco_limb_sequence = [\n",
    "    (0, 1),  # Nose to Left Eye\n",
    "    (0, 2),  # Nose to Right Eye\n",
    "    (1, 3),  # Left Eye to Left Ear\n",
    "    (2, 4),  # Right Eye to Right Ear\n",
    "    (5, 7),  # Left Shoulder to Left Elbow\n",
    "    (7, 9),  # Left Elbow to Left Wrist\n",
    "    (6, 8),  # Right Shoulder to Right Elbow\n",
    "    (8, 10), # Right Elbow to Right Wrist\n",
    "    (5, 6),  # Left Shoulder to Right Shoulder\n",
    "    (5, 11), # Left Shoulder to Left Hip\n",
    "    (6, 12), # Right Shoulder to Right Hip\n",
    "    (11, 12),# Left Hip to Right Hip\n",
    "    (11, 13),# Left Hip to Left Knee\n",
    "    (13, 15),# Left Knee to Left Ankle\n",
    "    (12, 14),# Right Hip to Right Knee\n",
    "    (14, 16) # Right Knee to Right Ankle\n",
    "]\n",
    "\n",
    "limb_sequence = [\n",
    "    (0,14),\n",
    "    (0,15),\n",
    "    (14,16),\n",
    "    (15,17),\n",
    "    (0,1),\n",
    "    (1,2),\n",
    "    (2,3),\n",
    "    (3,4),\n",
    "    (1,5),\n",
    "    (5,6),\n",
    "    (6,7),\n",
    "    (1,8),\n",
    "    (1,11),\n",
    "    (8,9),\n",
    "    (9,10),\n",
    "    (11,12),\n",
    "    (12,13),\n",
    "    ]\n",
    "\n",
    "mapping = {0:0,1:15,2:16,3:17,4:18,5:2,6:5,7:3,8:6,9:4,10:7,11:9,12:12,13:10,14:13,15:11,16:14}\n",
    "\n",
    "# COCO part list\n",
    "part_list = {\n",
    "    0: \"Nose\",\n",
    "    1: \"Left Eye\",\n",
    "    2: \"Right Eye\",\n",
    "    3: \"Left Ear\",\n",
    "    4: \"Right Ear\",\n",
    "    5: \"Left Shoulder\",\n",
    "    6: \"Right Shoulder\",\n",
    "    7: \"Left Elbow\",\n",
    "    8: \"Right Elbow\",\n",
    "    9: \"Left Wrist\",\n",
    "    10: \"Right Wrist\",\n",
    "    11: \"Left Hip\",\n",
    "    12: \"Right Hip\",\n",
    "    13: \"Left Knee\",\n",
    "    14: \"Right Knee\",\n",
    "    15: \"Left Ankle\",\n",
    "    16: \"Right Ankle\"\n",
    "}\n",
    "\n",
    "\n",
    "colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0],\n",
    "          [0, 255, 0], \\\n",
    "          [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255],\n",
    "          [85, 0, 255], \\\n",
    "          [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85],[255, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_best_instance(instances):\n",
    "    \"\"\"\n",
    "    Given a list of instances, return the index of the instance where keypoints are highest confidence.\n",
    "\n",
    "    Parameters:\n",
    "    instances (list): List of instances, where each instance contains a 'bbox' key with bounding box coordinates.\n",
    "\n",
    "    Returns:\n",
    "    int: The index of the instance whose center is closest to the frame center.\n",
    "    \"\"\"\n",
    "\n",
    "    best_score = 0\n",
    "\n",
    "    for e, instance in enumerate(instances):\n",
    "        \n",
    "        confidence = instance['keypoint_scores']\n",
    "\n",
    "        if len(confidence) == 17:\n",
    "            score = sum(confidence)\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                n_instance = e\n",
    "\n",
    "    \n",
    "    return n_instance\n",
    "\n",
    "\n",
    "def get_center_instance(instances, center_x, center_y):\n",
    "    \"\"\"\n",
    "    Given a list of instances, return the index of the instance whose center is closest to the center of the video frame.\n",
    "\n",
    "    Parameters:\n",
    "    instances (list): List of instances, where each instance contains a 'bbox' key with bounding box coordinates.\n",
    "    center_x (float): The x-coordinate of the frame center.\n",
    "    center_y (float): The y-coordinate of the frame center.\n",
    "\n",
    "    Returns:\n",
    "    int: The index of the instance whose center is closest to the frame center.\n",
    "    \"\"\"\n",
    "\n",
    "    distances = []\n",
    "    for e, instance in enumerate(instances):\n",
    "        \n",
    "        bbox_x, bbox_y, bbox_width, bbox_height = instance['bbox'][0]\n",
    "        bbox_center_x = bbox_x + bbox_width / 2\n",
    "        bbox_center_y = bbox_y + bbox_height / 2\n",
    "\n",
    "        # Calculate the Euclidean distance between the centers\n",
    "        distance = math.sqrt((bbox_center_x - center_x)**2 + (bbox_center_y - center_y)**2)\n",
    "        distances.append(distance)\n",
    "    \n",
    "    n_instance = distances.index(min(distances))\n",
    "    \n",
    "    return n_instance\n",
    "        \n",
    "\n",
    "def analyze_file(file_path, threshold=0.8):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    results = []\n",
    "    for frame in data:\n",
    "        frame_id = frame['frame_id']\n",
    "        if frame['instances']:  # Ensure there is at least one detection\n",
    "            instance_idx = get_best_instance(frame['instances'])\n",
    "            first_instance = frame['instances'][instance_idx]\n",
    "            keypoint_scores = first_instance['keypoint_scores']\n",
    "            \n",
    "            if len(keypoint_scores) != 17:\n",
    "                continue\n",
    "            \n",
    "            all_above_thr = all(score > threshold for score in keypoint_scores)\n",
    "            results.append({\n",
    "                'frame_id': frame_id,\n",
    "                'first_detection_keypoints': first_instance['keypoints'],\n",
    "                'first_detection_confidence': keypoint_scores,\n",
    "                'all_keypoints_above_thr': all_above_thr\n",
    "            })\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def find_continuous_good_blocks(analysis_results):\n",
    "    good_blocks = []\n",
    "    current_block = []\n",
    "    \n",
    "    for result in analysis_results:\n",
    "        if result['all_keypoints_above_thr']:\n",
    "            current_block.append(result)\n",
    "        else:\n",
    "            if len(current_block) >= 30:\n",
    "                good_blocks.append(current_block)\n",
    "            current_block = []\n",
    "    \n",
    "    # Check if the last block in the sequence is a good block\n",
    "    if len(current_block) >= 30:\n",
    "        good_blocks.append(current_block)\n",
    "    \n",
    "    return good_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def smooth_keypoints(block, window_size=3):\n",
    "    \"\"\"\n",
    "    Apply rolling average smoothing to keypoints in a block.\n",
    "    \n",
    "    :param block: A list of frames, each frame is a dictionary with 'first_detection_keypoints'.\n",
    "    :param window_size: Size of the rolling window for averaging.\n",
    "    :return: A new block with smoothed keypoints.\n",
    "    \"\"\"\n",
    "    # Convert block to numpy array for easier manipulation\n",
    "    keypoints_array = np.array([frame['first_detection_keypoints'] for frame in block])\n",
    "    num_frames, num_keypoints, _ = keypoints_array.shape\n",
    "    \n",
    "    # Initialize smoothed keypoints array\n",
    "    smoothed_keypoints = np.copy(keypoints_array)\n",
    "    \n",
    "    # Apply rolling average\n",
    "    for i in range(num_frames):\n",
    "        start = max(0, i - window_size // 2)\n",
    "        end = min(num_frames, i + window_size // 2 + 1)\n",
    "        smoothed_keypoints[i] = np.mean(keypoints_array[start:end], axis=0)\n",
    "    \n",
    "    # Update block with smoothed keypoints\n",
    "    smoothed_block = []\n",
    "    for i, frame in enumerate(block):\n",
    "        smoothed_frame = frame.copy()\n",
    "        smoothed_frame['first_detection_keypoints'] = smoothed_keypoints[i].tolist()\n",
    "        smoothed_block.append(smoothed_frame)\n",
    "    \n",
    "    return smoothed_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_keypoint_displacements(block):\n",
    "    \"\"\"\n",
    "    Calculate the total displacement for each keypoint in a block.\n",
    "    \n",
    "    :param block: List of frames, each frame is a dictionary with 'first_detection_keypoints'.\n",
    "    :return: A list with the total displacement for each keypoint.\n",
    "    \"\"\"\n",
    "    # Assuming each frame's keypoints are in the same order.\n",
    "    displacements = [0] * len(block[0]['first_detection_keypoints'])  # Initialize displacements\n",
    "    \n",
    "    for i in range(1, len(block)):\n",
    "        prev_keypoints = np.array(block[i-1]['first_detection_keypoints'])\n",
    "        curr_keypoints = np.array(block[i]['first_detection_keypoints'])\n",
    "        distances = np.linalg.norm(curr_keypoints - prev_keypoints, axis=1)\n",
    "        displacements += distances  # Update total displacement for each keypoint\n",
    "\n",
    "    displacements = np.array(displacements) / len(block)  # Normalize by number of frames\n",
    "    \n",
    "    return displacements\n",
    "\n",
    "def filter_blocks_by_displacement(blocks, threshold):\n",
    "    \"\"\"\n",
    "    Filter blocks to keep those where at least one keypoint's total displacement exceeds the threshold.\n",
    "    \n",
    "    :param blocks: List of blocks, each block is a list of frames.\n",
    "    :param threshold: Displacement threshold for filtering.\n",
    "    :return: Filtered list of blocks.\n",
    "    \"\"\"\n",
    "    filtered_blocks = []\n",
    "    \n",
    "    for block in blocks:\n",
    "        displacements = calculate_keypoint_displacements(block)\n",
    "        if np.mean(displacements) > threshold:\n",
    "            filtered_blocks.append(block)\n",
    "    \n",
    "    return filtered_blocks\n",
    "\n",
    "def get_orig_video_info(file):\n",
    "    file_path = file  # change to your own video path\n",
    "\n",
    "    try:\n",
    "        vid = cv2.VideoCapture(file_path)\n",
    "        height = vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        width = vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        center_x = (width) / 2\n",
    "        center_y = (height) / 2\n",
    "    except cv2.error as e:\n",
    "        print(f\"Caugt cv2 error, setting dummy params\")\n",
    "        width = 0\n",
    "        height = 0\n",
    "        center_x = 0\n",
    "        center_y = 0\n",
    "        fps = 0\n",
    "        \n",
    "    return width, height, center_x, center_y, fps\n",
    "\n",
    "\n",
    "def find_file_by_basename(directory, base_name):\n",
    "    \"\"\"\n",
    "    Find a file in the specified directory that has the given base name with any extension.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): The directory to search in.\n",
    "    - base_name (str): The base name of the file to find.\n",
    "\n",
    "    Returns:\n",
    "    - str: The path of the first matching file found, or None if no match is found.\n",
    "    \"\"\"\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if os.path.splitext(filename)[0].lower() == base_name.lower():\n",
    "            return os.path.join(directory, filename)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def reorder_keypoints(keypoints, confidence_scores):\n",
    "    \"\"\"\n",
    "    Reorder the keypoints to the OpenPose format.\n",
    "    The OpenPose format is as follows:\n",
    "    0-17: [nose, neck, right_shoulder, right_elbow, right_wrist, left_shoulder, left_elbow, left_wrist,\n",
    "           right_hip, right_knee, right_ankle, left_hip, left_knee, left_ankle, right_eye, left_eye, right_ear, left_ear]\n",
    "    The input 'keypoints' is a list of (x, y, c) tuples, where c is the confidence score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reorder the keypoints to the OpenPose format\n",
    "    keypoints = [keypoints[i] for i in [0, 17, 6, 8, 10, 5, 7, 9, 12, 14, 16, 11, 13, 15, 2, 1, 4, 3]]\n",
    "    confidence_scores = [confidence_scores[i] for i in [0, 17, 6, 8, 10, 5, 7, 9, 12, 14, 16, 11, 13, 15, 2, 1, 4, 3]]\n",
    "\n",
    "    return keypoints, confidence_scores\n",
    "\n",
    "def rescale_keypoints(keypoints, scale):\n",
    "    \"\"\"\n",
    "    Rescale the keypoints by the given scale.\n",
    "    The input 'keypoints' is a list of (x, y) tuples\n",
    "    \"\"\"\n",
    "\n",
    "    # Rescale the keypoints\n",
    "    keypoints = [(x * scale, y * scale) for (x, y) in keypoints]\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "\n",
    "def convert_coco_to_openpose(coco_keypoints, confidence_scores):\n",
    "    \"\"\"\n",
    "    Convert COCO keypoints to OpenPose keypoints with the neck keypoint as the midpoint between the two shoulders.\n",
    "    COCO keypoints format (17 keypoints): [nose, left_eye, right_eye, left_ear, right_ear,\n",
    "                                           left_shoulder, right_shoulder, left_elbow, right_elbow,\n",
    "                                           left_wrist, right_wrist, left_hip, right_hip,\n",
    "                                           left_knee, right_knee, left_ankle, right_ankle]\n",
    "    OpenPose keypoints format (18 keypoints): COCO keypoints + [neck]\n",
    "    The neck is not a part of COCO keypoints and is computed as the midpoint between the left and right shoulders.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assuming coco_keypoints is a list of (x, y) tuples\n",
    "    nose, left_eye, right_eye, left_ear, right_ear, \\\n",
    "    left_shoulder, right_shoulder, left_elbow, right_elbow, \\\n",
    "    left_wrist, right_wrist, left_hip, right_hip, \\\n",
    "    left_knee, right_knee, left_ankle, right_ankle = coco_keypoints\n",
    "\n",
    "    # Calculate the neck as the midpoint between left_shoulder and right_shoulder\n",
    "    neck_x = (left_shoulder[0] + right_shoulder[0]) / 2\n",
    "    neck_y = (left_shoulder[1] + right_shoulder[1]) / 2\n",
    "    neck = (neck_x, neck_y)\n",
    "\n",
    "\n",
    "    # Assuming coco_keypoints is a list of (x, y) tuples\n",
    "    c_nose, c_left_eye, c_right_eye, c_left_ear, c_right_ear, \\\n",
    "    c_left_shoulder, c_right_shoulder, c_left_elbow, c_right_elbow, \\\n",
    "    c_left_wrist, c_right_wrist, c_left_hip, c_right_hip, \\\n",
    "    c_left_knee, c_right_knee, c_left_ankle, c_right_ankle = confidence_scores\n",
    "\n",
    "    # Calculate the neck as the midpoint between left_shoulder and right_shoulder\n",
    "    c_neck = (c_left_shoulder + c_right_shoulder) / 2\n",
    "\n",
    "    # Construct the OpenPose keypoints including the neck\n",
    "    openpose_keypoints = [\n",
    "        nose, left_eye, right_eye, left_ear, right_ear,\n",
    "        left_shoulder, right_shoulder, left_elbow, right_elbow,\n",
    "        left_wrist, right_wrist, left_hip, right_hip,\n",
    "        left_knee, right_knee, left_ankle, right_ankle,\n",
    "        neck  # Adding the neck as the last keypoint\n",
    "    ]\n",
    "    \n",
    "    openpose_confidences = [\n",
    "        c_nose, c_left_eye, c_right_eye, c_left_ear, c_right_ear,\n",
    "        c_left_shoulder, c_right_shoulder, c_left_elbow, c_right_elbow,\n",
    "        c_left_wrist, c_right_wrist, c_left_hip, c_right_hip,\n",
    "        c_left_knee, c_right_knee, c_left_ankle, c_right_ankle,\n",
    "        c_neck  # Adding the neck as the last keypoint\n",
    "    ]\n",
    "\n",
    "    openpose_keypoints, confidences = reorder_keypoints(openpose_keypoints, openpose_confidences)\n",
    "    openpose_keypoints = rescale_keypoints(openpose_keypoints, 1)\n",
    "\n",
    "    return openpose_keypoints, confidences"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
