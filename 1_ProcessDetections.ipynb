{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "ngtR6tOyIFM-"
      },
      "outputs": [],
      "source": [
        "#download dependencies\n",
        "!wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/kinematics.py\n",
        "!wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/circstat.py\n",
        "!wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/processing.py\n",
        "!wget -P . https://raw.githubusercontent.com/quietscientist/gma_score_prediction_from_video/refs/heads/main/utils/skeleton.py\n",
        "\n",
        "#download example data or upload your own json annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "0pjaLpviIFNA"
      },
      "outputs": [],
      "source": [
        "%pip install scikit-video\n",
        "\n",
        "import sys, os, cv2, glob, json, gc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from itertools import chain\n",
        "from moviepy.editor import VideoFileClip\n",
        "import skvideo.io\n",
        "from tqdm import tqdm\n",
        "import circstat as CS\n",
        "import scipy as sc\n",
        "import math\n",
        "\n",
        "from processing import *\n",
        "from kinematics import *\n",
        "from skeleton import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# format files as pkl with openpose standard and bodypart labels\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "OVERWRITE = True\n",
        "USE_CENTER_INSTANCE = False\n",
        "USE_BEST_INSTANCE = True\n",
        "\n",
        "dataset = 'YT'\n",
        "json_path = f'./data/annotations'\n",
        "json_files = os.listdir(json_path)\n",
        "directory = f'./data'\n",
        "\n",
        "save_path = f'./pose_estimates/{dataset}_norm'\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "kp_mapping = {0:'Nose', 1:'Neck', 2:'RShoulder', 3:'RElbow', 4:'RWrist', 5:'LShoulder', 6:'LElbow',\n",
        "              7:'LWrist', 8:'RHip', 9:'RKnee', 10:'RAnkle', 11:'LHip',\n",
        "              12:'LKnee', 13:'LAnkle', 14:'REye', 15:'LEye', 16:'REar', 17:'LEar'}\n",
        "\n",
        "# Define the DataFrame columns as specified\n",
        "columns = ['video_number', 'video', 'bp', 'frame', 'x', 'y', 'c','fps', 'pixel_x', 'pixel_y', 'time', 'part_idx']\n",
        "data = []  # This will hold the data to be loaded into the DataFrame\n",
        "vid_info = pd.read_csv('./data/video_info.csv')\n",
        "\n",
        "for file_number, file in enumerate(tqdm(json_files)):\n",
        "    # Construct the full file path\n",
        "    file_path = os.path.join(json_path, file)\n",
        "    fname = file.split('.')[0]\n",
        "    interim = []\n",
        "\n",
        "    if not OVERWRITE and os.path.exists(f'{save_path}/{fname}.pkl'):\n",
        "        continue\n",
        "\n",
        "    # Open and load the JSON data\n",
        "    with open(file_path, 'r') as f:\n",
        "        frames = json.load(f)\n",
        "        info = vid_info[vid_info['video'] == fname]\n",
        "        center_x = info['center_x'].values[0]\n",
        "        center_y = info['center_y'].values[0]\n",
        "        pixel_x = info['width'].values[0]\n",
        "        pixel_y = info['height'].values[0]\n",
        "        fps = info['fps'].values[0]\n",
        "\n",
        "        # Iterate through each frame in the JSON file\n",
        "        for frame in frames:\n",
        "            frame_id = frame['frame_id']\n",
        "            if 'instances' in frame and len(frame['instances']) > 0:\n",
        "\n",
        "                if USE_CENTER_INSTANCE:\n",
        "                    instance_id = get_center_instance(frame['instances'], center_x, center_y)\n",
        "                elif USE_BEST_INSTANCE:\n",
        "                    instance_id = get_best_instance(frame['instances'])\n",
        "                else:\n",
        "                    instance_id = 0\n",
        "\n",
        "                keypoints = frame['instances'][instance_id]['keypoints']\n",
        "                confidence = frame['instances'][instance_id]['keypoint_scores']\n",
        "                keypoints, confidence = convert_coco_to_openpose(keypoints, confidence)\n",
        "\n",
        "                # Iterate through each keypoint\n",
        "                for part_idx, (x, y) in enumerate(keypoints):\n",
        "\n",
        "                    bp = kp_mapping[part_idx]\n",
        "                    fps = fps\n",
        "                    time = frame_id / fps\n",
        "                    c = confidence[part_idx]\n",
        "\n",
        "                    row = [file_number, fname, bp, frame_id, x, y, c, fps, pixel_x, pixel_y, time, part_idx]\n",
        "                    interim.append(row)\n",
        "\n",
        "    interim_df = pd.DataFrame(interim, columns=columns)\n",
        "    interim_df.to_pickle(f'{save_path}/{fname}.pkl')\n",
        "\n",
        "    del interim_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ7Dz7hYfoAg",
        "outputId": "cdb8a4ba-d1e0-4838-a9d7-ccdadc7b7ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [00:04<00:00,  4.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for pklfile in tqdm(os.listdir(save_path)):\n",
        "\n",
        "    interim_df = pd.read_pickle(f'{save_path}/{pklfile}')\n",
        "    interim_df.to_csv(f'{save_path}/pose_estimates_{dataset}.csv', mode='a', header=False, index=False)\n",
        "\n",
        "    del interim_df"
      ],
      "metadata": {
        "id": "gF9SA7KO1jbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'YT'\n",
        "\n",
        "csv_path = f'{save_path}/pose_estimates_{dataset}.csv'\n",
        "output_csv_path = f'{save_path}/pose_estimates_{dataset}_b.csv'\n",
        "chunksize = 1000  # Number of rows per chunk\n",
        "\n",
        "# Define the new headers\n",
        "new_headers = ['video_number', 'video', 'bp', 'frame', 'x', 'y', 'c', 'fps', 'pixel_x', 'pixel_y', 'time', 'part_idx']\n",
        "\n",
        "# Read the CSV file in chunks\n",
        "chunk_iterator = pd.read_csv(csv_path, chunksize=chunksize)\n",
        "\n",
        "# Process the first chunk\n",
        "first_chunk = next(chunk_iterator)\n",
        "first_chunk.columns = new_headers\n",
        "first_chunk.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# Process the rest of the chunks and append them to the new CSV file without headers\n",
        "for chunk in chunk_iterator:\n",
        "    chunk.columns = new_headers\n",
        "    chunk.to_csv(output_csv_path, mode='a', index=False, header=False)\n",
        "\n",
        "# rename the csv file\n",
        "os.rename(csv_path, f'{save_path}pose_estimates_{dataset}_x.csv')\n",
        "os.rename(output_csv_path, csv_path)\n",
        "\n",
        "#remove other files\n",
        "os.remove(f'{save_path}/pose_estimates_{dataset}_b.csv')\n",
        "os.remove(f'{save_path}/pose_estimates_{dataset}_x.csv')"
      ],
      "metadata": {
        "id": "ERK1DQ-92DsG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}